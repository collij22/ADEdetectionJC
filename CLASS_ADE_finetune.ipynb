{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sweep = [16,0.15,0.000005,0.001,8]\n",
    "\n",
    "pretrained_bert = 'michiyasunaga/BioLinkBERT-base'\n",
    "#pretrained_bert = 'dmis-lab/biobert-base-cased-v1.2'\n",
    "#pretrained_bert = 'cimm-kzn/endr-bert'\n",
    "#pretrained_bert = 'SpanBERT/spanbert-base-cased'\n",
    "#pretrained_bert = 'emilyalsentzer/Bio_ClinicalBERT'\n",
    "#pretrained_bert = 'dmis-lab/biobert-v1.1'\n",
    "#pretrained_bert = 'allenai/scibert_scivocab_uncased'\n",
    "\n",
    "#pretrained_bert = 'bert-large-uncased'\n",
    "optim_batch_size = best_sweep[0]\n",
    "optim_learning_rate = best_sweep[2]\n",
    "optim_epochs = best_sweep[4]\n",
    "optim_dropout = best_sweep[1]\n",
    "weight_decay = best_sweep[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_pretrained_bert = pretrained_bert.replace('/', '')\n",
    "if pretrained_bert == 'bert-large-uncased':\n",
    "    model_name = \"ADE_CLASS_\"+pretrained_bert\n",
    "else:\n",
    "    model_name = \"ADE_CLASS_\"+pretrained_bert.split('/')[1]\n",
    "\n",
    "optim_model_name=pretrained_bert\n",
    "\n",
    "#TRAINING FILE\n",
    "use_huggingface = True\n",
    "training_file = \"**training**.csv\"\n",
    "# training_file = \"**training**.csv\"\n",
    "column1_AEtext = \"text\" #\"Example\"\n",
    "column2_AEflag = \"label\" #\"AE Flag\"\n",
    "train_test_split_percent = 0.20\n",
    "balance_multiplier = 1.0\n",
    "#batch_size = 3\n",
    "balance_me = True\n",
    "#balance_me = False\n",
    "\n",
    "#TEST FILE\n",
    "test_file = \"**test**.csv\"\n",
    "# test_file = \"**test**.csv\"\n",
    "test_column1_AEtext = \"Example\"\n",
    "test_column2_AEflag = \"AE Flag\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, BertConfig, AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "from tqdm.notebook import tqdm\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score,f1_score,precision_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_huggingface = True\n",
    "if use_huggingface == True:\n",
    "    dataset = load_dataset(\"ade_corpus_v2\",\"Ade_corpus_v2_classification\")\n",
    "else:\n",
    "    dataset = pd.read_csv(training_file, encoding='unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_huggingface == True:\n",
    "    #convert to pandas dataframe\n",
    "    df = pd.DataFrame(dataset['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_AEs = df[column2_AEflag].value_counts()[1]\n",
    "balance_number = int(num_AEs * balance_multiplier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_AEs = 6821\n",
      "balance_number = 6821\n",
      "balance_multiplier = 1.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"num_AEs = {num_AEs}\\nbalance_number = {balance_number}\\nbalance_multiplier = {balance_multiplier}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(balance_me == True):\n",
    "    d_NoAE = df[df[column2_AEflag]==0]\n",
    "    shuffle_d_NoAE = d_NoAE.sample(frac=1,random_state=42)[:balance_number]\n",
    "    d_AE = df[df[column2_AEflag]==1]\n",
    "    df = pd.concat([shuffle_d_NoAE,d_AE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    6821\n",
       "1    6821\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[column2_AEflag].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[column1_AEtext]\n",
    "y = df[column2_AEflag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val,y_train, y_val = train_test_split(X,y, test_size=train_test_split_percent,stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_val,X_test_data,y_val, y_test_data = train_test_split(X_test,y_test, test_size=0.95,stratify=y_test, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.shape,X_test_data.shape, y_train.shape,y_test_data.shape, X_val.shape,y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(model_name,batch_size):\n",
    "    #tokenizer = BertTokenizer.from_pretrained(model_name, do_lower_case=True)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, add_prefix_space=True, use_fast=False)\n",
    "    \n",
    "    encoded_data_train = tokenizer.batch_encode_plus(X_train.values,\n",
    "                                                    add_special_tokens=True,\n",
    "                                                    return_attention_mask=True,\n",
    "                                                    pad_to_max_length=True,\n",
    "                                                    max_length=512,\n",
    "                                                    return_tensors='pt')\n",
    "    encoded_data_val = tokenizer.batch_encode_plus(X_val.values,\n",
    "                                                    add_special_tokens=True,\n",
    "                                                    return_attention_mask=True,\n",
    "                                                    pad_to_max_length=True,\n",
    "                                                    max_length=512,\n",
    "                                                    return_tensors='pt')\n",
    "    input_ids_train = encoded_data_train['input_ids']\n",
    "    attention_masks_train = encoded_data_train['attention_mask']\n",
    "    #labels = torch.tensor(dataset['AE Flag'].replace(label_dict).values)\n",
    "    labels_train = torch.tensor(y_train.values)\n",
    "    input_ids_val = encoded_data_val['input_ids']\n",
    "    attention_masks_val = encoded_data_val['attention_mask']\n",
    "    #labels = torch.tensor(dataset['AE Flag'].replace(label_dict).values)\n",
    "    labels_val = torch.tensor(y_val.values)\n",
    "    dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "    dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n",
    "    dataloader_train = DataLoader(dataset_train, sampler=RandomSampler(dataset_train), batch_size=batch_size)\n",
    "    dataloader_validation = DataLoader(dataset_val, sampler = SequentialSampler(dataset_val), batch_size=batch_size)\n",
    "    return dataloader_train,dataloader_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkLeul\n",
    "\n",
    "def ret_model():\n",
    "    \n",
    "    configuration = AutoConfig.from_pretrained(pretrained_bert)\n",
    "    configuration.hidden_dropout_prob = optim_dropout #check\n",
    "    configuration.attention_probs_dropout_prob = optim_dropout #check\n",
    "    configuration.num_labels = 2\n",
    "    configuration.output_attentions = False\n",
    "    configuration.output_hidden_states = False\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(pretrained_bert,config=configuration)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score_func(preds,labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(batch_size,model_name,learning_rate,epochs,dropout): #checkleul, added dropout\n",
    "    model=ret_model()\n",
    "    dataloader_train,dataloader_validation =prepare_data(model_name,batch_size)\n",
    "    optimizer = AdamW(model.parameters(),\n",
    "                    lr = learning_rate, \n",
    "                    eps = 1e-8,weight_decay=weight_decay)\n",
    "    total_steps = len(dataloader_train) * epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                                num_warmup_steps = 0, \n",
    "                                                num_training_steps = total_steps)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    t0 = time.time()\n",
    "    for epoch_i in range(0, epochs):\n",
    "        print(\"\")\n",
    "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "        print('Training...')\n",
    "        total_train_loss = 0\n",
    "        model.train()\n",
    "        for step, batch in enumerate(dataloader_train):\n",
    "            if step % 40 == 0 and not step == 0:\n",
    "                print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(dataloader_train)))\n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "            model.zero_grad()        \n",
    "            outputs = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask, \n",
    "                            labels=b_labels)\n",
    "            loss = outputs[0]\n",
    "            total_train_loss += loss.item()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "        avg_train_loss = total_train_loss / len(dataloader_train)            \n",
    "        print(\"\")\n",
    "        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "        print(\"\")\n",
    "        print(\"Running Validation...\")\n",
    "        model.eval()\n",
    "        total_eval_loss = 0\n",
    "        predictions, true_vals = [], []\n",
    "        #nb_eval_steps = 0\n",
    "        for batch in dataloader_validation:        \n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)        \n",
    "            with torch.no_grad():        \n",
    "                outputs = model(b_input_ids,\n",
    "                                token_type_ids=None,\n",
    "                                attention_mask=b_input_mask,\n",
    "                                labels=b_labels)\n",
    "            loss = outputs[0]\n",
    "            logits = outputs[1]\n",
    "            total_eval_loss += loss.item()\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label_ids = b_labels.to('cpu').numpy()\n",
    "            predictions.append(logits)\n",
    "            true_vals.append(label_ids)\n",
    "        predictions = np.concatenate(predictions, axis=0)\n",
    "        true_vals = np.concatenate(true_vals, axis=0)\n",
    "        val_f1 = f1_score_func(predictions, true_vals)            \n",
    "        print(f'Val_f1: {val_f1}')\n",
    "        avg_val_loss = total_eval_loss / len(dataloader_validation)\n",
    "        print(f'Validation loss: {avg_val_loss}')            \n",
    "        if epoch_i+1 == epochs:\n",
    "            torch.save(model.state_dict(), f'{cropped_pretrained_bert}_{epoch_i+1}.model')\n",
    "    model.load_state_dict(torch.load(f'{cropped_pretrained_bert}_{epochs}.model', map_location=torch.device('cuda')))\n",
    "    training_time = format_time(time.time() - t0)\n",
    "    return model,training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(text,tokenizer,device,model):\n",
    "    encoded_input = tokenizer(text, return_tensors=\"pt\",truncation=True,max_length=512,padding=True)\n",
    "    encoded_input.to(device)\n",
    "    output = model(**encoded_input)\n",
    "    res = output.logits[0].detach().to('cpu').numpy()\n",
    "    return np.argmax(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificationreporter(model):\n",
    "    #tokenizer = BertTokenizer.from_pretrained(model_name, do_lower_case=True)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(pretrained_bert, add_prefix_space=True, use_fast=False)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    results=[]\n",
    "    x=X_val.values\n",
    "    y=y_val.values\n",
    "    for text in x:\n",
    "        results.append(classify(text,tokenizer,device,model))\n",
    "    ground_truth=y\n",
    "    conf = confusion_matrix(ground_truth, results)\n",
    "    print('Confusion Matrix :')\n",
    "    print(conf)\n",
    "    print('Accuracy Score :',accuracy_score(ground_truth, results))\n",
    "    print('Report : ')\n",
    "    print(classification_report(ground_truth, results))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at michiyasunaga/BioLinkBERT-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "c:\\Users\\jonlc\\anaconda3\\envs\\bestpytorch\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "c:\\Users\\jonlc\\anaconda3\\envs\\bestpytorch\\Lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 8 ========\n",
      "Training...\n",
      "  Batch    40  of    683.\n",
      "  Batch    80  of    683.\n",
      "  Batch   120  of    683.\n",
      "  Batch   160  of    683.\n",
      "  Batch   200  of    683.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model,training_time \u001b[38;5;241m=\u001b[39m train(optim_batch_size,optim_model_name,optim_learning_rate,optim_epochs,optim_dropout)\n",
      "Cell \u001b[1;32mIn[19], line 35\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(batch_size, model_name, learning_rate, epochs, dropout)\u001b[0m\n\u001b[0;32m     33\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     34\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m---> 35\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     36\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     37\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\jonlc\\anaconda3\\envs\\bestpytorch\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:68\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     66\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     67\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m---> 68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jonlc\\anaconda3\\envs\\bestpytorch\\Lib\\site-packages\\torch\\optim\\optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    369\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    370\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    371\u001b[0m             )\n\u001b[1;32m--> 373\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    376\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jonlc\\anaconda3\\envs\\bestpytorch\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jonlc\\anaconda3\\envs\\bestpytorch\\Lib\\site-packages\\transformers\\optimization.py:468\u001b[0m, in \u001b[0;36mAdamW.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    466\u001b[0m exp_avg\u001b[38;5;241m.\u001b[39mmul_(beta1)\u001b[38;5;241m.\u001b[39madd_(grad, alpha\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m beta1))\n\u001b[0;32m    467\u001b[0m exp_avg_sq\u001b[38;5;241m.\u001b[39mmul_(beta2)\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[1;32m--> 468\u001b[0m denom \u001b[38;5;241m=\u001b[39m exp_avg_sq\u001b[38;5;241m.\u001b[39msqrt()\u001b[38;5;241m.\u001b[39madd_(group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meps\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    470\u001b[0m step_size \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorrect_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m]:  \u001b[38;5;66;03m# No bias correction for Bert\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model,training_time = train(optim_batch_size,optim_model_name,optim_learning_rate,optim_epochs,optim_dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      "[[1141  224]\n",
      " [  87 1277]]\n",
      "Accuracy Score : 0.8860388420666911\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.84      0.88      1365\n",
      "           1       0.85      0.94      0.89      1364\n",
      "\n",
      "    accuracy                           0.89      2729\n",
      "   macro avg       0.89      0.89      0.89      2729\n",
      "weighted avg       0.89      0.89      0.89      2729\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classificationreporter(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reporter(model,x_data,y_data):\n",
    "    #tokenizer = BertTokenizer.from_pretrained(model_name, do_lower_case=True)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(pretrained_bert, add_prefix_space=True, use_fast=False)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    results=[]\n",
    "    for text in x_data.values:\n",
    "        results.append(classify(text,tokenizer,device,model))\n",
    "    ground_truth=y_data.values\n",
    "    conf = confusion_matrix(ground_truth, results)\n",
    "    recall = recall_score(ground_truth, results, pos_label=1)\n",
    "    f1 = f1_score(ground_truth, results, pos_label=1)\n",
    "    precision = precision_score(ground_truth, results, pos_label=1)\n",
    "    return conf, recall,f1,precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first time\n",
    "columns=[\"model_name\",\"Training Time\",\"precision\",\"recall\",\"f1_Score\",\"True Positives\",\"False Positives\",\"True Negatives\",\"False Negatives\",\"Epochs\",\"Learning Rate\",\"Drop Out\",\"Batch Size\",\"Weight Decay\"]\n",
    "# df = pd.DataFrame(columns=columns)\n",
    "# df.to_csv(\"results.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_row(model):\n",
    "  df=pd.read_csv(\"results.csv\")\n",
    "  x=X_val\n",
    "  y=y_val\n",
    "  conf,recall,f1,precision=reporter(model,x,y)\n",
    "  data=[model_name,training_time,precision,recall,f1,conf[0][0],conf[0][1],conf[1][1],conf[1][0],optim_epochs,optim_learning_rate,optim_dropout,optim_batch_size,weight_decay]\n",
    "  df.loc[len(df)] = data\n",
    "  df.to_csv(\"results.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_row(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bestpytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
