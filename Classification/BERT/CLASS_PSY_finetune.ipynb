{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sweep = [16,0.2,0.000005,0.001,8]\n",
    "\n",
    "\n",
    "#pretrained_bert = 'michiyasunaga/BioLinkBERT-base'\n",
    "#pretrained_bert = 'dmis-lab/biobert-base-cased-v1.2'\n",
    "#pretrained_bert = 'cimm-kzn/endr-bert'\n",
    "#pretrained_bert = 'SpanBERT/spanbert-base-cased'\n",
    "#pretrained_bert = 'emilyalsentzer/Bio_ClinicalBERT'\n",
    "#pretrained_bert = 'dmis-lab/biobert-v1.1'\n",
    "#pretrained_bert = 'bert-large-uncased'\n",
    "pretrained_bert = 'allenai/scibert_scivocab_uncased'\n",
    "\n",
    "#pretrained_bert = 'allenai/biomed_roberta_base' \n",
    "#pretrained_bert = 'microsoft/BiomedNLP-BiomedBERT-large-uncased-abstract'\n",
    "\n",
    "\n",
    "optim_batch_size = best_sweep[0]\n",
    "optim_learning_rate = best_sweep[2]\n",
    "optim_epochs = best_sweep[4]\n",
    "optim_dropout = best_sweep[1]\n",
    "weight_decay = best_sweep[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_pretrained_bert = pretrained_bert.replace('/', '')\n",
    "if pretrained_bert == 'bert-large-uncased':\n",
    "    model_name = \"PSY_CLASS_\"+pretrained_bert\n",
    "else:\n",
    "    model_name = \"PSY_CLASS_\"+pretrained_bert.split('/')[1]\n",
    "\n",
    "optim_model_name=pretrained_bert\n",
    "\n",
    "#TRAINING FILE\n",
    "use_huggingface = False\n",
    "training_file = \"PsyTAR_JC.csv\"\n",
    "# training_file = \"**training**.csv\"\n",
    "column1_AEtext = \"test\" #\"Example\"\n",
    "column2_AEflag = \"label\" #\"AE Flag\"\n",
    "train_test_split_percent = 0.3\n",
    "balance_multiplier = 1.0\n",
    "#batch_size = 3\n",
    "balance_me = True\n",
    "#balance_me = False\n",
    "\n",
    "#TEST FILE\n",
    "test_file = \"**test**.csv\"\n",
    "# test_file = \"**test**.csv\"\n",
    "test_column1_AEtext = \"test\"\n",
    "test_column2_AEflag = \"label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, BertConfig, AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "from tqdm.notebook import tqdm\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score,f1_score,precision_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use_huggingface = False\n",
    "if use_huggingface == True:\n",
    "    dataset = load_dataset(\"ade_corpus_v2\",\"Ade_corpus_v2_classification\")\n",
    "else:\n",
    "    df = pd.read_csv(training_file, encoding='unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_huggingface == True:\n",
    "    #convert to pandas dataframe\n",
    "    df = pd.DataFrame(dataset['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_AEs = df[column2_AEflag].value_counts()[1]\n",
    "balance_number = int(num_AEs * balance_multiplier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_AEs = 2168\n",
      "balance_number = 2168\n",
      "balance_multiplier = 1.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"num_AEs = {num_AEs}\\nbalance_number = {balance_number}\\nbalance_multiplier = {balance_multiplier}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(balance_me == True):\n",
    "    d_NoAE = df[df[column2_AEflag]==0]\n",
    "    shuffle_d_NoAE = d_NoAE.sample(frac=1,random_state=42)[:balance_number]\n",
    "    d_AE = df[df[column2_AEflag]==1]\n",
    "    df = pd.concat([shuffle_d_NoAE,d_AE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    2168\n",
       "1    2168\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[column2_AEflag].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[column1_AEtext]\n",
    "y = df[column2_AEflag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val,y_train, y_val = train_test_split(X,y, test_size=train_test_split_percent,stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(model_name,batch_size):\n",
    "    #tokenizer = BertTokenizer.from_pretrained(model_name, do_lower_case=True)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, add_prefix_space=True, use_fast=False)\n",
    "    \n",
    "    encoded_data_train = tokenizer.batch_encode_plus(X_train.values,\n",
    "                                                    add_special_tokens=True,\n",
    "                                                    return_attention_mask=True,\n",
    "                                                    pad_to_max_length=True,\n",
    "                                                    max_length=512,\n",
    "                                                    return_tensors='pt')\n",
    "    encoded_data_val = tokenizer.batch_encode_plus(X_val.values,\n",
    "                                                    add_special_tokens=True,\n",
    "                                                    return_attention_mask=True,\n",
    "                                                    pad_to_max_length=True,\n",
    "                                                    max_length=512,\n",
    "                                                    return_tensors='pt')\n",
    "    input_ids_train = encoded_data_train['input_ids']\n",
    "    attention_masks_train = encoded_data_train['attention_mask']\n",
    "    #labels = torch.tensor(dataset['AE Flag'].replace(label_dict).values)\n",
    "    labels_train = torch.tensor(y_train.values)\n",
    "    input_ids_val = encoded_data_val['input_ids']\n",
    "    attention_masks_val = encoded_data_val['attention_mask']\n",
    "    #labels = torch.tensor(dataset['AE Flag'].replace(label_dict).values)\n",
    "    labels_val = torch.tensor(y_val.values)\n",
    "    dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "    dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n",
    "    dataloader_train = DataLoader(dataset_train, sampler=RandomSampler(dataset_train), batch_size=batch_size)\n",
    "    dataloader_validation = DataLoader(dataset_val, sampler = SequentialSampler(dataset_val), batch_size=batch_size)\n",
    "    return dataloader_train,dataloader_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkLeul\n",
    "\n",
    "def ret_model():\n",
    "    \n",
    "    configuration = AutoConfig.from_pretrained(pretrained_bert)\n",
    "    configuration.hidden_dropout_prob = optim_dropout #check\n",
    "    configuration.attention_probs_dropout_prob = optim_dropout #check\n",
    "    configuration.num_labels = 2\n",
    "    configuration.output_attentions = False\n",
    "    configuration.output_hidden_states = False\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(pretrained_bert,config=configuration)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score_func(preds,labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(batch_size,model_name,learning_rate,epochs,dropout): #checkleul, added dropout\n",
    "    model=ret_model()\n",
    "    dataloader_train,dataloader_validation =prepare_data(model_name,batch_size)\n",
    "    optimizer = AdamW(model.parameters(),\n",
    "                    lr = learning_rate, \n",
    "                    eps = 1e-8,weight_decay=weight_decay)\n",
    "    total_steps = len(dataloader_train) * epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                                num_warmup_steps = 0, \n",
    "                                                num_training_steps = total_steps)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    t0 = time.time()\n",
    "    for epoch_i in range(0, epochs):\n",
    "        print(\"\")\n",
    "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "        print('Training...')\n",
    "        total_train_loss = 0\n",
    "        model.train()\n",
    "        for step, batch in enumerate(dataloader_train):\n",
    "            if step % 40 == 0 and not step == 0:\n",
    "                print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(dataloader_train)))\n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "            model.zero_grad()        \n",
    "            outputs = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask, \n",
    "                            labels=b_labels)\n",
    "            loss = outputs[0]\n",
    "            total_train_loss += loss.item()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "        avg_train_loss = total_train_loss / len(dataloader_train)            \n",
    "        print(\"\")\n",
    "        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "        print(\"\")\n",
    "        print(\"Running Validation...\")\n",
    "        model.eval()\n",
    "        total_eval_loss = 0\n",
    "        predictions, true_vals = [], []\n",
    "        #nb_eval_steps = 0\n",
    "        for batch in dataloader_validation:        \n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)        \n",
    "            with torch.no_grad():        \n",
    "                outputs = model(b_input_ids,\n",
    "                                token_type_ids=None,\n",
    "                                attention_mask=b_input_mask,\n",
    "                                labels=b_labels)\n",
    "            loss = outputs[0]\n",
    "            logits = outputs[1]\n",
    "            total_eval_loss += loss.item()\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label_ids = b_labels.to('cpu').numpy()\n",
    "            predictions.append(logits)\n",
    "            true_vals.append(label_ids)\n",
    "        predictions = np.concatenate(predictions, axis=0)\n",
    "        true_vals = np.concatenate(true_vals, axis=0)\n",
    "        val_f1 = f1_score_func(predictions, true_vals)            \n",
    "        print(f'Val_f1: {val_f1}')\n",
    "        avg_val_loss = total_eval_loss / len(dataloader_validation)\n",
    "        print(f'Validation loss: {avg_val_loss}')            \n",
    "        if epoch_i+1 == epochs:\n",
    "            torch.save(model.state_dict(), f'{cropped_pretrained_bert}_{epoch_i+1}.model')\n",
    "    model.load_state_dict(torch.load(f'{cropped_pretrained_bert}_{epochs}.model', map_location=torch.device('cuda')))\n",
    "    training_time = format_time(time.time() - t0)\n",
    "    return model,training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(text,tokenizer,device,model):\n",
    "    encoded_input = tokenizer(text, return_tensors=\"pt\",truncation=True,max_length=512,padding=True)\n",
    "    encoded_input.to(device)\n",
    "    output = model(**encoded_input)\n",
    "    res = output.logits[0].detach().to('cpu').numpy()\n",
    "    return np.argmax(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificationreporter(model):\n",
    "    #tokenizer = BertTokenizer.from_pretrained(model_name, do_lower_case=True)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(pretrained_bert, add_prefix_space=True, use_fast=False)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    results=[]\n",
    "    x=X_val.values\n",
    "    y=y_val.values\n",
    "    for text in x:\n",
    "        results.append(classify(text,tokenizer,device,model))\n",
    "    ground_truth=y\n",
    "    conf = confusion_matrix(ground_truth, results)\n",
    "    print('Confusion Matrix :')\n",
    "    print(conf)\n",
    "    print('Accuracy Score :',accuracy_score(ground_truth, results))\n",
    "    print('Report : ')\n",
    "    print(classification_report(ground_truth, results))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "c:\\Users\\jonlc\\anaconda3\\envs\\bestpytorch\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "c:\\Users\\jonlc\\anaconda3\\envs\\bestpytorch\\Lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 8 ========\n",
      "Training...\n",
      "  Batch    40  of    190.\n",
      "  Batch    80  of    190.\n",
      "  Batch   120  of    190.\n",
      "  Batch   160  of    190.\n",
      "\n",
      "  Average training loss: 0.54\n",
      "\n",
      "Running Validation...\n",
      "Val_f1: 0.7955368173070985\n",
      "Validation loss: 0.43350476826109535\n",
      "\n",
      "======== Epoch 2 / 8 ========\n",
      "Training...\n",
      "  Batch    40  of    190.\n",
      "  Batch    80  of    190.\n",
      "  Batch   120  of    190.\n",
      "  Batch   160  of    190.\n",
      "\n",
      "  Average training loss: 0.42\n",
      "\n",
      "Running Validation...\n",
      "Val_f1: 0.8285927820897587\n",
      "Validation loss: 0.39657862657090515\n",
      "\n",
      "======== Epoch 3 / 8 ========\n",
      "Training...\n",
      "  Batch    40  of    190.\n",
      "  Batch    80  of    190.\n",
      "  Batch   120  of    190.\n",
      "  Batch   160  of    190.\n",
      "\n",
      "  Average training loss: 0.37\n",
      "\n",
      "Running Validation...\n",
      "Val_f1: 0.8347126236632042\n",
      "Validation loss: 0.3981866228689508\n",
      "\n",
      "======== Epoch 4 / 8 ========\n",
      "Training...\n",
      "  Batch    40  of    190.\n",
      "  Batch    80  of    190.\n",
      "  Batch   120  of    190.\n",
      "  Batch   160  of    190.\n",
      "\n",
      "  Average training loss: 0.34\n",
      "\n",
      "Running Validation...\n",
      "Val_f1: 0.8234535596872722\n",
      "Validation loss: 0.423103967908679\n",
      "\n",
      "======== Epoch 5 / 8 ========\n",
      "Training...\n",
      "  Batch    40  of    190.\n",
      "  Batch    80  of    190.\n",
      "  Batch   120  of    190.\n",
      "  Batch   160  of    190.\n",
      "\n",
      "  Average training loss: 0.31\n",
      "\n",
      "Running Validation...\n",
      "Val_f1: 0.8447128008328472\n",
      "Validation loss: 0.39179890630085296\n",
      "\n",
      "======== Epoch 6 / 8 ========\n",
      "Training...\n",
      "  Batch    40  of    190.\n",
      "  Batch    80  of    190.\n",
      "  Batch   120  of    190.\n",
      "  Batch   160  of    190.\n",
      "\n",
      "  Average training loss: 0.29\n",
      "\n",
      "Running Validation...\n",
      "Val_f1: 0.836792715662508\n",
      "Validation loss: 0.40852976392772866\n",
      "\n",
      "======== Epoch 7 / 8 ========\n",
      "Training...\n",
      "  Batch    40  of    190.\n",
      "  Batch    80  of    190.\n",
      "  Batch   120  of    190.\n",
      "  Batch   160  of    190.\n",
      "\n",
      "  Average training loss: 0.28\n",
      "\n",
      "Running Validation...\n",
      "Val_f1: 0.8407521914769768\n",
      "Validation loss: 0.40507996668357676\n",
      "\n",
      "======== Epoch 8 / 8 ========\n",
      "Training...\n",
      "  Batch    40  of    190.\n",
      "  Batch    80  of    190.\n",
      "  Batch   120  of    190.\n",
      "  Batch   160  of    190.\n",
      "\n",
      "  Average training loss: 0.27\n",
      "\n",
      "Running Validation...\n",
      "Val_f1: 0.8376096443239277\n",
      "Validation loss: 0.4085422329513765\n"
     ]
    }
   ],
   "source": [
    "model,training_time = train(optim_batch_size,optim_model_name,optim_learning_rate,optim_epochs,optim_dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      "[[522 129]\n",
      " [ 82 568]]\n",
      "Accuracy Score : 0.8378170637970792\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.80      0.83       651\n",
      "           1       0.81      0.87      0.84       650\n",
      "\n",
      "    accuracy                           0.84      1301\n",
      "   macro avg       0.84      0.84      0.84      1301\n",
      "weighted avg       0.84      0.84      0.84      1301\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classificationreporter(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reporter(model,x_data,y_data):\n",
    "    #tokenizer = BertTokenizer.from_pretrained(model_name, do_lower_case=True)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(pretrained_bert, add_prefix_space=True, use_fast=False)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    results=[]\n",
    "    for text in x_data.values:\n",
    "        results.append(classify(text,tokenizer,device,model))\n",
    "    ground_truth=y_data.values\n",
    "    conf = confusion_matrix(ground_truth, results)\n",
    "    recall = recall_score(ground_truth, results, pos_label=1)\n",
    "    f1 = f1_score(ground_truth, results, pos_label=1)\n",
    "    precision = precision_score(ground_truth, results, pos_label=1)\n",
    "    return conf, recall,f1,precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first time\n",
    "columns=[\"model_name\",\"Training Time\",\"precision\",\"recall\",\"f1_Score\",\"True Positives\",\"False Positives\",\"True Negatives\",\"False Negatives\",\"Epochs\",\"Learning Rate\",\"Drop Out\",\"Batch Size\",\"Weight Decay\"]\n",
    "# df = pd.DataFrame(columns=columns)\n",
    "# df.to_csv(\"results.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_row(model):\n",
    "  df=pd.read_csv(\"results.csv\")\n",
    "  x=X_val\n",
    "  y=y_val\n",
    "  conf,recall,f1,precision=reporter(model,x,y)\n",
    "  data=[model_name,training_time,precision,recall,f1,conf[0][0],conf[0][1],conf[1][1],conf[1][0],optim_epochs,optim_learning_rate,optim_dropout,optim_batch_size,weight_decay]\n",
    "  df.loc[len(df)] = data\n",
    "  df.to_csv(\"results.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_row(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bestpytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
