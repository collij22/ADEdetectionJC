{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sweep = [8,0.1,0.000005,0.001,8]\n",
    "#dataset_name = \"preprocessed_cadec\"\n",
    "dataset_name = \"ADE_corpus_output3\"\n",
    "\n",
    "pretrained_bert = 'michiyasunaga/BioLinkBERT-base'\n",
    "#pretrained_bert = 'dmis-lab/biobert-base-cased-v1.2'\n",
    "#pretrained_bert = 'cimm-kzn/endr-bert'\n",
    "#pretrained_bert = 'SpanBERT/spanbert-base-cased'\n",
    "#pretrained_bert = 'emilyalsentzer/Bio_ClinicalBERT'\n",
    "#pretrained_bert = 'dmis-lab/biobert-v1.1'\n",
    "#pretrained_bert = 'bert-large-uncased'\n",
    "#pretrained_bert = 'allenai/scibert_scivocab_uncased'\n",
    "#pretrained_bert = 'allenai/biomed_roberta_base' \n",
    "#pretrained_bert = 'microsoft/BiomedNLP-BiomedBERT-large-uncased-abstract'\n",
    "\n",
    "optim_batch_size = best_sweep[0]\n",
    "optim_learning_rate = best_sweep[2]\n",
    "optim_epochs = best_sweep[4]\n",
    "optim_dropout = best_sweep[1]\n",
    "optim_weight_decay = best_sweep[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset,DataLoader,RandomSampler,SequentialSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForTokenClassification,BertConfig,AutoConfig,AutoModelForTokenClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from seqeval.metrics import f1_score, accuracy_score, precision_score, recall_score, classification_report,performance_measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"{dataset_name}.csv\")\n",
    "\n",
    "pretrained_save = pretrained_bert.replace('/','_')\n",
    "\n",
    "if dataset_name == \"preprocessed_cadec\":\n",
    "    model_name = \"CADEC_NER_\"+pretrained_bert.split('/')[1]\n",
    "else:\n",
    "    model_name = \"ADE_NER_\"+pretrained_bert.split('/')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_list(text):\n",
    "    return eval(text)\n",
    "df['sentences']=df['sentences'].apply(ret_list)\n",
    "df['labels']=df['labels'].apply(ret_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = train_test_split(df,test_size=0.15,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3823, 675)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train),len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = train['sentences'].to_list()\n",
    "labels = train['labels'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(pretrained_bert,do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TokenLength = [len(tokenizer.encode(' '.join(i),add_special_tokens=True)) for i in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum length: 4 tokens\n",
      "Maximum length: 103 tokens\n",
      "Average length: 24 tokens\n"
     ]
    }
   ],
   "source": [
    "print(\"Minimum length: {:,} tokens\".format(min(TokenLength)))\n",
    "print(\"Maximum length: {:,} tokens\".format(max(TokenLength)))\n",
    "print(\"Average length: {:,} tokens\".format(int(np.median(TokenLength))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = set()\n",
    "for label in labels:\n",
    "    for l in label:\n",
    "        unique_labels.add(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I-drug', 'I-effect', 'O', 'B-drug', 'B-effect']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tags=list(unique_labels)\n",
    "data_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I-drug', 'I-effect', 'O', 'B-drug', 'B-effect']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_values = data_tags\n",
    "tag_values.append(\"PAD\")\n",
    "tag2idx = {t:i for i,t in enumerate(tag_values)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I-drug': 0, 'I-effect': 1, 'O': 2, 'B-drug': 3, 'B-effect': 4, 'PAD': 5}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_allign_labels(sentences,labels):\n",
    "    tokenized_sentences=[]\n",
    "    alligned_labels=[]\n",
    "    for word,label in zip(sentences,labels):\n",
    "        tokenized_word = tokenizer.tokenize(word)\n",
    "        subwords = len(tokenized_word)\n",
    "\n",
    "        tokenized_sentences.extend(tokenized_word)\n",
    "        \n",
    "        if subwords>1 and label!='O':\n",
    "            c=label.replace('B','I')\n",
    "            alligned_labels.extend([label]+ [c]*(subwords-1))\n",
    "        else:\n",
    "            alligned_labels.extend([label]*subwords)\n",
    "\n",
    "    return tokenized_sentences,alligned_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_data = [tokenize_and_allign_labels(sent,label) for sent,label in zip(sentences,labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_texts = [sentandlabel[0] for sentandlabel in tokenized_data]\n",
    "new_labels = [sentandlabel[1] for sentandlabel in tokenized_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(text) for text in tokenized_texts],maxlen=130,dtype=\"long\",\n",
    "                          value=0.0,truncating=\"post\",padding=\"post\")\n",
    "label_tags = pad_sequences([[tag2idx.get(l) for l in label] for label in new_labels],maxlen=130,value=tag2idx[\"PAD\"],padding=\"post\",dtype=\"long\",truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_masks=[[float(i!=0.0) for i in ii] for ii in input_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs=torch.tensor(input_ids,dtype=torch.long)\n",
    "train_labels=torch.tensor(label_tags,dtype=torch.long)\n",
    "train_mask=torch.tensor(attention_masks,dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_dataloader():\n",
    "    batch_size = optim_batch_size\n",
    "    train_dataset = TensorDataset(train_inputs,train_mask,train_labels)\n",
    "    train_dataloader = DataLoader(train_dataset,sampler=RandomSampler(train_dataset),batch_size=batch_size)\n",
    "\n",
    "    return train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_model():\n",
    "\n",
    "    configuration = AutoConfig.from_pretrained(pretrained_bert)\n",
    "    configuration.hidden_dropout_prob = optim_dropout\n",
    "    configuration.attention_probs_dropout_prob = optim_dropout\n",
    "    configuration.num_labels = len(tag2idx)\n",
    "    configuration.output_attentions = False\n",
    "    configuration.output_hidden_states = False\n",
    "\n",
    "    model = AutoModelForTokenClassification.from_pretrained(pretrained_bert,config=configuration)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_optim(model):\n",
    "    print(f\"learning_rate = {optim_learning_rate}\")\n",
    "    optimizer = AdamW(model.parameters(),\n",
    "                      lr = optim_learning_rate,\n",
    "                      eps = 1e-8,weight_decay = optim_weight_decay)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_scheduler(optimizer, dataloader_train):\n",
    "    epochs = optim_epochs\n",
    "    total_steps = len(dataloader_train) * epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                                num_warmup_steps = 0,\n",
    "                                                num_training_steps = total_steps)\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def train(epochs):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model=ret_model()\n",
    "    model.to(device)\n",
    "    dataloader_train = ret_dataloader() #, dataloader_validation\n",
    "    optimizer = ret_optim(model)\n",
    "    scheduler = ret_scheduler(optimizer, dataloader_train)\n",
    "    epochs = epochs\n",
    "    loss_values, val_loss = [], []\n",
    "    t0= time.time()\n",
    "    for epoch_i in range(epochs):\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        for step, batch in enumerate(dataloader_train):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            b_input_ids, b_input_mask, b_labels = batch\n",
    "            model.zero_grad()\n",
    "            outputs = model(b_input_ids, token_type_ids=None,\n",
    "            attention_mask=b_input_mask,\n",
    "            labels=b_labels)\n",
    "            loss = outputs[0]\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "        avg_train_loss = total_loss / len(dataloader_train)\n",
    "        print(\"Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "        print(\"\")\n",
    "        if epoch_i+1 == epochs:\n",
    "            torch.save(model.state_dict(), f'ner_{dataset_name}_{pretrained_save}_{epoch_i+1}.model')\n",
    "        training_time = format_time(time.time()-t0)\n",
    "    model.load_state_dict(torch.load(f'ner_{dataset_name}_{pretrained_save}_{epochs}.model', map_location=torch.device('cuda')))\n",
    "\n",
    "    return model,training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at michiyasunaga/BioLinkBERT-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate = 5e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonlc\\AppData\\Local\\Temp\\ipykernel_36272\\1609290690.py:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.21\n",
      "\n",
      "Average training loss: 0.04\n",
      "\n",
      "Average training loss: 0.03\n",
      "\n",
      "Average training loss: 0.03\n",
      "\n",
      "Average training loss: 0.02\n",
      "\n",
      "Average training loss: 0.02\n",
      "\n",
      "Average training loss: 0.02\n",
      "\n",
      "Average training loss: 0.02\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model,training_time=train(optim_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pytorch_model.bin: 100%|██████████| 431M/431M [00:38<00:00, 11.2MB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/collij22/ner_ADE_corpus_output3_michiyasunaga_BioLinkBERT-base_2.0/commit/aa0a91346fb200d4dd88d359e1fc51dfabecfb82', commit_message='Upload tokenizer', commit_description='', oid='aa0a91346fb200d4dd88d359e1fc51dfabecfb82', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version =2.0\n",
    "model.push_to_hub(f\"ner_{dataset_name}_{pretrained_save}_{version}\",token=\"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\")\n",
    "tokenizer.push_to_hub(f\"ner_{dataset_name}_{pretrained_save}_{version}\",token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I-drug': 0, 'I-effect': 1, 'O': 2, 'B-drug': 3, 'B-effect': 4, 'PAD': 5}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = test['sentences'].to_list()\n",
    "test_labels = test['labels'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_testdataloader(test_sentences,test_labels):\n",
    "    tokenized_data = [tokenize_and_allign_labels(sent,label) for sent,label in zip(test_sentences,test_labels)]\n",
    "    tokenized_texts = [sentandlabel[0] for sentandlabel in tokenized_data]\n",
    "    new_labels = [sentandlabel[1] for sentandlabel in tokenized_data]\n",
    "    test_input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(text) for text in tokenized_texts],maxlen=130,dtype=\"long\",\n",
    "                          value=0.0,truncating=\"post\",padding=\"post\")\n",
    "    test_label_tags = pad_sequences([[tag2idx.get(l) for l in label] for label in new_labels],maxlen=130,value=tag2idx[\"PAD\"],padding=\"post\",dtype=\"long\",truncating=\"post\")\n",
    "    test_attention_masks=[[float(i!=0.0) for i in ii] for ii in test_input_ids]\n",
    "    test_inputs = torch.tensor(test_input_ids,dtype=torch.long)\n",
    "    test_labels_id=torch.tensor(test_label_tags,dtype=torch.long)\n",
    "    test_mask=torch.tensor(test_attention_masks,dtype=torch.long)\n",
    "    batch_size = optim_batch_size\n",
    "    test_dataset = TensorDataset(test_inputs,test_mask,test_labels_id)\n",
    "    test_dataloader = DataLoader(test_dataset,sampler=RandomSampler(test_dataset),batch_size=batch_size)\n",
    "    return test_dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    test_dataloader = ret_testdataloader(test_sentences,test_labels)\n",
    "    model.eval()\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    eval_loss = 0\n",
    "    predictions , true_labels = [], []\n",
    "    for batch in test_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        with torch.no_grad():\n",
    "            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "        logits = outputs[1].detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
    "        #print(predictions)\n",
    "        true_labels.extend(label_ids)\n",
    "        eval_loss += outputs[0].mean().item()\n",
    "        nb_eval_examples += b_input_ids.size(0)\n",
    "        nb_eval_steps += 1\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    print(\"Test loss: {0:.2f}\".format(eval_loss))\n",
    "    prediction_tags = []\n",
    "    validation_tags = []\n",
    "    for item1,item2  in zip(predictions, true_labels):\n",
    "        p1,v1= [],[]\n",
    "        for i in range(len(item2)):\n",
    "            if tag_values[item2[i]] != \"PAD\":\n",
    "                p1.append(tag_values[item1[i]])\n",
    "                v1.append(tag_values[item2[i]])\n",
    "        prediction_tags.append(p1)\n",
    "        validation_tags.append(v1)\n",
    "    acc_score = accuracy_score(prediction_tags, validation_tags)\n",
    "    p_score = precision_score(prediction_tags, validation_tags)\n",
    "    r_score = recall_score(prediction_tags, validation_tags)\n",
    "    f1_s = f1_score(prediction_tags, validation_tags)\n",
    "    report = classification_report(prediction_tags, validation_tags)\n",
    "    #conf = confusion_matrix(prediction_tags, validation_tags)\n",
    "    conf = performance_measure(validation_tags,prediction_tags)\n",
    "    print(\"Test accuracy_score: {0:.2f}\".format(acc_score))\n",
    "    print(\"Test precision_score: {0:.2f}\".format(p_score))\n",
    "    print(\"Test recall_score: {0:.2f}\".format(r_score))\n",
    "    print(\"Test f1_score: {0:.2f}\".format(f1_s))\n",
    "    print(\"Classification Report\")\n",
    "    print((report))\n",
    "    return eval_loss,acc_score,p_score,r_score,f1_s,report,conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.03\n",
      "Test accuracy_score: 0.95\n",
      "Test precision_score: 0.89\n",
      "Test recall_score: 0.81\n",
      "Test f1_score: 0.85\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AD       0.00      0.00      0.00         3\n",
      "        drug       0.93      0.89      0.91       818\n",
      "      effect       0.85      0.75      0.80       973\n",
      "\n",
      "   micro avg       0.89      0.81      0.85      1794\n",
      "   macro avg       0.59      0.55      0.57      1794\n",
      "weighted avg       0.88      0.81      0.85      1794\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "eval_loss,acc_score,p_score,r_score,f1_s,report,conf=get_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first time\n",
    "columns=[\"model_name\",\"Training_time\",\"precision\",\"recall\",\"f1_Score\",\"True Positives\",\"False Positives\",\"True Negatives\",\"False Negatives\",\"Epochs\",\"Learning Rate\",\"Drop Out\",\"Batch Size\",\"Weight Decay\"]\n",
    "# df = pd.DataFrame(columns=columns)\n",
    "# df.to_csv(\"results.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_row():\n",
    "  global eval_loss,acc_score,p_score,r_score,f1_s,report,conf\n",
    "  df=pd.read_csv(\"results.csv\")\n",
    "  data=[model_name,training_time,p_score,r_score,f1_s,conf[\"TP\"],conf[\"FP\"],conf[\"TN\"],conf[\"FN\"],optim_epochs,optim_learning_rate,optim_dropout,optim_batch_size,optim_weight_decay]\n",
    "  df.loc[len(df)] = data\n",
    "  df.to_csv(\"results.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_row()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kerasenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
