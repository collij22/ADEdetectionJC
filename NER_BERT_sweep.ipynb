{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_name = \"preprocessed_cadec\"\n",
    "dataset_name = \"ADE_corpus_output3\"\n",
    "\n",
    "#pretrained_bert = 'SpanBERT/spanbert-base-cased'\n",
    "#pretrained_bert = 'allenai/scibert_scivocab_uncased'\n",
    "#pretrained_bert = 'dmis-lab/biobert-base-cased-v1.2'\n",
    "# retrained_bert = 'cimm-kzn/endr-bert'\n",
    "#pretrained_bert = 'emilyalsentzer/Bio_ClinicalBERT'\n",
    "#pretrained_bert = 'dmis-lab/biobert-v1.1'\n",
    "#pretrained_bert = 'microsoft/BiomedNLP-BiomedBERT-large-uncased-abstract'\n",
    "#pretrained_bert = 'bert-large-uncased'\n",
    "pretrained_bert = 'michiyasunaga/BioLinkBERT-large'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\pandas\\__init__.py:23\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m _hard_dependencies, _dependency, _missing_dependencies\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# numpy compat\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     24\u001b[0m         is_numpy_dev \u001b[38;5;28;01mas\u001b[39;00m _is_numpy_dev,  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401,E501\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     )\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m _err:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     _module \u001b[38;5;241m=\u001b[39m _err\u001b[38;5;241m.\u001b[39mname\n",
      "File \u001b[1;32mc:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\pandas\\compat\\__init__.py:27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompressors\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_numpy_dev\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyarrow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     28\u001b[0m     pa_version_under7p0,\n\u001b[0;32m     29\u001b[0m     pa_version_under8p0,\n\u001b[0;32m     30\u001b[0m     pa_version_under9p0,\n\u001b[0;32m     31\u001b[0m     pa_version_under11p0,\n\u001b[0;32m     32\u001b[0m     pa_version_under13p0,\n\u001b[0;32m     33\u001b[0m     pa_version_under14p0,\n\u001b[0;32m     34\u001b[0m     pa_version_under14p1,\n\u001b[0;32m     35\u001b[0m )\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_typing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m F\n",
      "File \u001b[1;32mc:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\pandas\\compat\\pyarrow.py:8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Version\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m----> 8\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpa\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     _palv \u001b[38;5;241m=\u001b[39m Version(Version(pa\u001b[38;5;241m.\u001b[39m__version__)\u001b[38;5;241m.\u001b[39mbase_version)\n\u001b[0;32m     11\u001b[0m     pa_version_under7p0 \u001b[38;5;241m=\u001b[39m _palv \u001b[38;5;241m<\u001b[39m Version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m7.0.0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\pyarrow\\__init__.py:65\u001b[0m\n\u001b[0;32m     63\u001b[0m _gc_enabled \u001b[38;5;241m=\u001b[39m _gc\u001b[38;5;241m.\u001b[39misenabled()\n\u001b[0;32m     64\u001b[0m _gc\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_lib\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _gc_enabled:\n\u001b[0;32m     67\u001b[0m     _gc\u001b[38;5;241m.\u001b[39menable()\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:404\u001b[0m, in \u001b[0;36mparent\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "import keras\n",
    "import wandb\n",
    "import statistics\n",
    "from keras.utils import pad_sequences\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, BertForTokenClassification, AdamW, BertConfig, AutoTokenizer, AutoModelForSequenceClassification, AutoModelForTokenClassification, AutoConfig, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from seqeval.metrics import f1_score,accuracy_score, precision_score, recall_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"{dataset_name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['Intravenous', 'azithromycin', '-', 'induced'...</td>\n",
       "      <td>['O', 'B-drug', 'O', 'O', 'B-effect', 'O']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['Immobilization', ',', 'while', \"Paget's\", 'b...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['Unaccountable', 'severe', 'hypercalcemia', '...</td>\n",
       "      <td>['O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['METHODS', ':', 'We', 'report', 'two', 'cases...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['Naproxen', ',', 'the', 'most', 'common', 'of...</td>\n",
       "      <td>['B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences  \\\n",
       "0  ['Intravenous', 'azithromycin', '-', 'induced'...   \n",
       "1  ['Immobilization', ',', 'while', \"Paget's\", 'b...   \n",
       "2  ['Unaccountable', 'severe', 'hypercalcemia', '...   \n",
       "3  ['METHODS', ':', 'We', 'report', 'two', 'cases...   \n",
       "4  ['Naproxen', ',', 'the', 'most', 'common', 'of...   \n",
       "\n",
       "                                              labels  \n",
       "0         ['O', 'B-drug', 'O', 'O', 'B-effect', 'O']  \n",
       "1  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n",
       "2  ['O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O'...  \n",
       "3  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect'...  \n",
       "4  ['B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjon-l-collins\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_list(text):\n",
    "    return eval(text)\n",
    "df['sentences'] = df['sentences'].apply(ret_list)\n",
    "df['labels'] = df['labels'].apply(ret_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3823, 675)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = train['sentences'].to_list()\n",
    "labels = train['labels'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'random'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = {\n",
    "        'name': 'val_loss',\n",
    "        'goal': 'minimize'\n",
    "}\n",
    "sweep_config['metric'] = metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-28 02:24:50.918878\n"
     ]
    }
   ],
   "source": [
    "print(str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: zcsnbat3\n",
      "Sweep URL: https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3\n"
     ]
    }
   ],
   "source": [
    "parameters_dict = {\n",
    "    'learning_rate': {\n",
    "        'values': [5e-5,1e-5,5e-6]\n",
    "    },\n",
    "    'batch_size': {\n",
    "        'values': [4,8,16] \n",
    "        },\n",
    "    \n",
    "    'dropout': {\n",
    "          'values': [0.1,0.15,0.2,0.3]\n",
    "        },\n",
    "    \n",
    "    'epochs': {\n",
    "        'values': [17]},#20\n",
    "    \n",
    "    'weight_decay': {\n",
    "        'values': [0.001,0.01]\n",
    "    }   \n",
    " \n",
    "}\n",
    "sweep_config['parameters'] = parameters_dict\n",
    "pretrained_bert2 = pretrained_bert.replace('/','')\n",
    "sweep_id = wandb.sweep(sweep_config, project=f\"NER_{dataset_name}_{pretrained_bert2}_{str(datetime.datetime.now())[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(pretrained_bert, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TokenLength = [len(tokenizer.encode(' '.join(i),add_special_tokens=True)) for i in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum length: 4 tokens\n",
      "Maximum length: 103 tokens\n",
      "Average length: 24 tokens\n"
     ]
    }
   ],
   "source": [
    "print(\"Minimum length: {:,} tokens\".format(min(TokenLength)))\n",
    "print(\"Maximum length: {:,} tokens\".format(max(TokenLength)))\n",
    "print(\"Average length: {:,} tokens\".format(int(np.median(TokenLength))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-drug', 'B-effect', 'I-drug', 'I-effect', 'O'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_labels = set()\n",
    "for label in labels:\n",
    "    for l in label:\n",
    "        unique_labels.add(l)\n",
    "        \n",
    "unique_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-drug', 'I-drug', 'O', 'I-effect', 'B-effect']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tags = list(unique_labels)\n",
    "data_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-drug': 0, 'I-drug': 1, 'O': 2, 'I-effect': 3, 'B-effect': 4, 'PAD': 5}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_values = data_tags\n",
    "tag_values.append(\"PAD\")\n",
    "tag2idx = {t: i for i, t in enumerate(tag_values)}\n",
    "tag2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OBJECTIVE', ':', 'To', 'report', 'the', 'case', 'of', 'a', 'young', 'woman', 'with', 'Graves', \"'\", 'disease', 'in', 'whom', 'ototoxicity', 'developed', 'because', 'of', 'propylthiouracil', '(', 'PTU', ')-', 'induced', 'antineutrophil', 'cytoplasmic', 'antibody', '(', 'ANCA)-associated', 'vasculitis', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(sentences[0])\n",
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(sentences, labels):\n",
    "    tokenized_sentences = []\n",
    "    aligned_labels = []\n",
    "    for word, label in zip(sentences, labels):\n",
    "        tokenized_word = tokenizer.tokenize(word)\n",
    "        subwords = len(tokenized_word)\n",
    "        \n",
    "        tokenized_sentences.extend(tokenized_word)\n",
    "        \n",
    "        if subwords > 1 and label != \"O\":\n",
    "            c = label.replace(\"B-\",\"I-\")\n",
    "            aligned_labels.extend([label] + [c] * (subwords - 1))\n",
    "        else:\n",
    "            aligned_labels.extend([label]*subwords)\n",
    "          \n",
    "    return tokenized_sentences, aligned_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_data = [tokenize_and_align_labels(sent, label) for sent, label in zip(sentences, labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['objective', ':', 'to', 'report', 'the', 'case', 'of', 'a', 'young', 'woman', 'with', 'graves', \"'\", 'disease', 'in', 'whom', 'ot', '##otoxicity', 'developed', 'because', 'of', 'propyl', '##thio', '##ura', '##cil', '(', 'pt', '##u', ')', '-', 'induced', 'antine', '##utr', '##ophil', 'cytoplasmic', 'antibody', '(', 'anca', ')', '-', 'associated', 'vasculitis', '.'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'])\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_texts = [sentandlabel[0] for sentandlabel in tokenized_data]\n",
    "new_labels = [sentandlabel[1] for sentandlabel in tokenized_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['objective', ':', 'to', 'report', 'the', 'case', 'of', 'a', 'young', 'woman', 'with', 'graves', \"'\", 'disease', 'in', 'whom', 'ot', '##otoxicity', 'developed', 'because', 'of', 'propyl', '##thio', '##ura', '##cil', '(', 'pt', '##u', ')', '-', 'induced', 'antine', '##utr', '##ophil', 'cytoplasmic', 'antibody', '(', 'anca', ')', '-', 'associated', 'vasculitis', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_texts[0])\n",
    "print(new_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(text) for text in tokenized_texts],\n",
    "                          maxlen=130, dtype=\"long\", value=0.0, \n",
    "                          truncating=\"post\", padding=\"post\")\n",
    "label_tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in new_labels],maxlen=130, value=tag2idx[\"PAD\"], padding=\"post\",dtype=\"long\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2833    29  1701  2255  1680  2632  1685    42  3612  6764  1715 19492\n",
      "    10  2174  1682  6314  7833  9397  2829  3058  1685 14429 23410 10694\n",
      " 15800    11  4349  1029    12    16  2326 20567  3813  4149  7314  3762\n",
      "    11 21403    12    16  2138 14479    17     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0]\n",
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 4 3 2 2 2 2 2 2 2 2 0 1 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n"
     ]
    }
   ],
   "source": [
    "print(input_ids[0])\n",
    "print(label_tags[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130\n",
      "130\n"
     ]
    }
   ],
   "source": [
    "print(len(input_ids[0]))\n",
    "print(len(label_tags[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_masks = [[float(i != 0.0) for i in ii] for ii in input_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids, val_ids, train_tags, val_tags, train_masks, val_masks = train_test_split(input_ids, label_tags, attention_masks, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3058, 765)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ids), len(val_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1802,  2255,    42, ...,     0,     0,     0],\n",
       "       [ 5388,  1715, 15748, ...,     0,     0,     0],\n",
       "       [12771,  1884, 13248, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [15503,  8386,  1705, ...,     0,     0,     0],\n",
       "       [ 1802,  2143,    42, ...,     0,     0,     0],\n",
       "       [ 3612,  2564,  5114, ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = torch.tensor(train_ids,dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_inputs = torch.tensor(val_ids,dtype=torch.long)\n",
    "train_labels = torch.tensor(train_tags,dtype=torch.long)\n",
    "val_labels = torch.tensor(val_tags,dtype=torch.long)\n",
    "train_mask = torch.tensor(train_masks,dtype=torch.long)\n",
    "val_mask = torch.tensor(val_masks,dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "# batch_size = 12\n",
    "# train_dataset = TensorDataset(train_inputs, train_mask, train_labels)\n",
    "# train_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=batch_size)\n",
    "\n",
    "# validation_dataset = TensorDataset(val_inputs, val_mask, val_labels)\n",
    "# validation_dataloader = DataLoader(validation_dataset, sampler=SequentialSampler(validation_dataset), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_dataloader():\n",
    "    batch_size = wandb.config.batch_size\n",
    "    train_dataset = TensorDataset(train_inputs, train_mask, train_labels)\n",
    "    train_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=batch_size)\n",
    "    \n",
    "    validation_dataset = TensorDataset(val_inputs, val_mask, val_labels)\n",
    "    validation_dataloader = DataLoader(validation_dataset, sampler=SequentialSampler(validation_dataset), batch_size=batch_size)\n",
    "    return train_dataloader, validation_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_model():\n",
    "    \n",
    "    configuration = AutoConfig.from_pretrained(pretrained_bert)\n",
    "    configuration.hidden_dropout_prob = wandb.config.dropout\n",
    "    configuration.attention_probs_dropout_prob = wandb.config.dropout\n",
    "    configuration.num_labels = len(tag2idx)\n",
    "    configuration.output_attentions = False\n",
    "    configuration.output_hidden_states = False\n",
    "\n",
    "    model = AutoModelForTokenClassification.from_pretrained(pretrained_bert,config=configuration)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import BertForTokenClassification, AdamW, BertConfig\n",
    "# model = BertForTokenClassification.from_pretrained(\n",
    "#     pretrained_bert,\n",
    "#     num_labels=len(tag2idx),\n",
    "#     output_attentions = False,\n",
    "#     output_hidden_states = False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_optim(model):\n",
    "    print(f\"learning_rate = {wandb.config.learning_rate}\")\n",
    "    optimizer = AdamW(model.parameters(),\n",
    "                      lr = wandb.config.learning_rate, \n",
    "                      eps = 1e-8,weight_decay = wandb.config.weight_decay)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_scheduler(optimizer, dataloader_train):\n",
    "    epochs = wandb.config.epochs\n",
    "    total_steps = len(dataloader_train) * epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                                num_warmup_steps = 0, \n",
    "                                                num_training_steps = total_steps)\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    wandb.init()\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model=ret_model()\n",
    "    model.to(device)\n",
    "    dataloader_train, dataloader_validation = ret_dataloader()\n",
    "    optimizer = ret_optim(model)\n",
    "    scheduler = ret_scheduler(optimizer, dataloader_train) \n",
    "    epochs = wandb.config.epochs \n",
    "    loss_values, val_loss = [], []\n",
    "    for epoch_i in range(epochs):  \n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        for step, batch in enumerate(dataloader_train):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            b_input_ids, b_input_mask, b_labels = batch\n",
    "            model.zero_grad()\n",
    "            outputs = model(b_input_ids, token_type_ids=None,\n",
    "            attention_mask=b_input_mask,\n",
    "            labels=b_labels)\n",
    "            loss = outputs[0]\n",
    "            wandb.log({\"train_batch_loss\":loss.item()})\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "        avg_train_loss = total_loss / len(dataloader_train)\n",
    "        wandb.log({\"train_loss\": avg_train_loss, \"epoch\": epoch_i})\n",
    "        print(\"Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "        print(\"\")\n",
    "        print(\"Running Validation...\")\n",
    "        model.eval()\n",
    "        nb_eval_steps, nb_eval_examples = 0, 0\n",
    "        eval_loss = 0\n",
    "        predictions , true_labels = [], []\n",
    "        for batch in dataloader_validation:\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            b_input_ids, b_input_mask, b_labels = batch\n",
    "            with torch.no_grad():\n",
    "                outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "            logits = outputs[1].detach().cpu().numpy()\n",
    "            label_ids = b_labels.to('cpu').numpy()\n",
    "            predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
    "            #print(predictions)\n",
    "            #predictions.append(logits)\n",
    "            true_labels.extend(label_ids)\n",
    "            eval_loss += outputs[0].mean().item()\n",
    "            nb_eval_examples += b_input_ids.size(0)\n",
    "            nb_eval_steps += 1\n",
    "        eval_loss = eval_loss / nb_eval_steps\n",
    "        wandb.log({\"val_loss\": eval_loss,\"epoch\": epoch_i})\n",
    "        print(\"Validation loss: {0:.2f}\".format(eval_loss))\n",
    "        \n",
    "        prediction_tags = []\n",
    "        validation_tags = []\n",
    "        for item1,item2  in zip(predictions, true_labels):\n",
    "          p1,v1= [],[]\n",
    "          for i in range(len(item2)):\n",
    "            if tag_values[item2[i]] != \"PAD\":\n",
    "              p1.append(tag_values[item1[i]])\n",
    "              v1.append(tag_values[item2[i]])\n",
    "          prediction_tags.append(p1)\n",
    "          validation_tags.append(v1)\n",
    "        #predictions_tags = [tag_values[p_i] for p, l in zip(predictions, true_labels) for p_i, l_i in zip(p, l) if tag_values[l_i] != \"PAD\"]\n",
    "        #validation_tags = [tag_values[l_i] for l in true_labels for l_i in l if tag_values[l_i] != \"PAD\"]\n",
    "        # predictions = np.concatenate(predictions, axis=0) #added\n",
    "        # true_vals = np.concatenate(true_labels, axis=0) #added\n",
    "        # predictions_tags = np.argmax(predictions, axis=2).flatten()\n",
    "        # validation_tags = true_vals.flatten()\n",
    "        acc_score = accuracy_score(prediction_tags, validation_tags)\n",
    "        p_score = precision_score(prediction_tags, validation_tags)\n",
    "        r_score = recall_score(prediction_tags, validation_tags)\n",
    "        f1_s = f1_score(prediction_tags, validation_tags)\n",
    "        \n",
    "        # f1_score = f1_score(predictions_tags, validation_tags)\n",
    "        wandb.log({\"val_accuracy_score\": acc_score,\"epoch\": epoch_i})\n",
    "        wandb.log({\"precision score\": p_score,\"epoch\": epoch_i})\n",
    "        wandb.log({\"recall score\": r_score,\"epoch\": epoch_i})\n",
    "        wandb.log({\"val_f1_score\": f1_s,\"epoch\": epoch_i})\n",
    "        \n",
    "        # wandb.log({\"val_f1_score\": f1_score,\"epoch\": epoch_i})\n",
    "        print(\"Validation Accuracy: {0:.2f}\".format(acc_score))\n",
    "        print(\"Validation F1 Score: {0:.2f}\".format(f1_s))\n",
    "        print(\"Recall Score: {0:.2f}\".format(r_score))\n",
    "        print(\"Precision Score: {0:.2f}\".format(p_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 24oq2wdy with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.01\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\AI projects\\NER_keras\\wandb\\run-20240228_022507-24oq2wdy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/24oq2wdy' target=\"_blank\">solar-sweep-1</a></strong> to <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/24oq2wdy' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/24oq2wdy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-large-uncased-abstract and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate = 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonlc\\AppData\\Local\\Temp\\ipykernel_22768\\3119774215.py:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.10\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.83\n",
      "Recall Score: 0.77\n",
      "Precision Score: 0.91\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.02\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.87\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.87\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.02\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.87\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.91\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.06\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.87\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.06\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.06\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.90\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>precision score</td><td>█▂▃▁▅▃▇▆▅▆▆▆▆▆▆▆▇</td></tr><tr><td>recall score</td><td>▁▅█▇▇▇▇█▇▇▇██████</td></tr><tr><td>train_batch_loss</td><td>█▂▁▂▂▂▁▂▁▃▂▁▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy_score</td><td>▁▆█▇▅▇▇█▇▇███▇██▇</td></tr><tr><td>val_f1_score</td><td>▁▃▇▅▆▆▇█▆▇▇██▇███</td></tr><tr><td>val_loss</td><td>▂▁▂▁▃▃▄▄▆▆▆▆▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>16</td></tr><tr><td>precision score</td><td>0.90119</td></tr><tr><td>recall score</td><td>0.86298</td></tr><tr><td>train_batch_loss</td><td>1e-05</td></tr><tr><td>train_loss</td><td>0.00103</td></tr><tr><td>val_accuracy_score</td><td>0.95819</td></tr><tr><td>val_f1_score</td><td>0.88167</td></tr><tr><td>val_loss</td><td>0.05707</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">solar-sweep-1</strong> at: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/24oq2wdy' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/24oq2wdy</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240228_022507-24oq2wdy\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qyyv8spc with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.001\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\AI projects\\NER_keras\\wandb\\run-20240228_024531-qyyv8spc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/qyyv8spc' target=\"_blank\">elated-sweep-2</a></strong> to <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/qyyv8spc' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/qyyv8spc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-large-uncased-abstract and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate = 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonlc\\AppData\\Local\\Temp\\ipykernel_22768\\3119774215.py:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.34\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.09\n",
      "Validation Accuracy: 0.84\n",
      "Validation F1 Score: 0.43\n",
      "Recall Score: 0.42\n",
      "Precision Score: 0.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.09\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.92\n",
      "Validation F1 Score: 0.72\n",
      "Recall Score: 0.65\n",
      "Precision Score: 0.82\n",
      "Average training loss: 0.05\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.93\n",
      "Validation F1 Score: 0.78\n",
      "Recall Score: 0.71\n",
      "Precision Score: 0.87\n",
      "Average training loss: 0.04\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.81\n",
      "Recall Score: 0.75\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.04\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.81\n",
      "Recall Score: 0.75\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.82\n",
      "Recall Score: 0.77\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.80\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.79\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.80\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.80\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.81\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.81\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.81\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.81\n",
      "Precision Score: 0.89\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>precision score</td><td>▁▇███████████████</td></tr><tr><td>recall score</td><td>▁▅▆▇▇▇█▇█████████</td></tr><tr><td>train_batch_loss</td><td>█▄▃▂▃▂▂▁▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy_score</td><td>▁▆▇▇▇▇█▇█████████</td></tr><tr><td>val_f1_score</td><td>▁▆▇▇▇▇███████████</td></tr><tr><td>val_loss</td><td>█▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>16</td></tr><tr><td>precision score</td><td>0.88769</td></tr><tr><td>recall score</td><td>0.81306</td></tr><tr><td>train_batch_loss</td><td>0.01571</td></tr><tr><td>train_loss</td><td>0.01879</td></tr><tr><td>val_accuracy_score</td><td>0.94855</td></tr><tr><td>val_f1_score</td><td>0.84874</td></tr><tr><td>val_loss</td><td>0.03291</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">elated-sweep-2</strong> at: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/qyyv8spc' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/qyyv8spc</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240228_024531-qyyv8spc\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qknm4ro1 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.01\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\AI projects\\NER_keras\\wandb\\run-20240228_030538-qknm4ro1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/qknm4ro1' target=\"_blank\">likely-sweep-3</a></strong> to <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/qknm4ro1' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/qknm4ro1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-large-uncased-abstract and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate = 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonlc\\AppData\\Local\\Temp\\ipykernel_22768\\3119774215.py:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.11\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.83\n",
      "Recall Score: 0.78\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.02\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.06\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.06\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.06\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.90\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>precision score</td><td>▆▄▆▁▇▆▇▇▅▅▃▆▇▇▇██</td></tr><tr><td>recall score</td><td>▁▅▇▇▅█▆▆██▆▇▇▇▇▇▆</td></tr><tr><td>train_batch_loss</td><td>█▅▂▃▂▂▁▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy_score</td><td>▁▇█▅▃▅▅▅▆▆▅▄▆▆▆▆▅</td></tr><tr><td>val_f1_score</td><td>▁▅▇▆▅█▇▆▇█▅▇█▇▇▇▇</td></tr><tr><td>val_loss</td><td>▁▁▂▃▃▄▃▆▄▆▅▇▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>16</td></tr><tr><td>precision score</td><td>0.89525</td></tr><tr><td>recall score</td><td>0.83737</td></tr><tr><td>train_batch_loss</td><td>2e-05</td></tr><tr><td>train_loss</td><td>0.00108</td></tr><tr><td>val_accuracy_score</td><td>0.95294</td></tr><tr><td>val_f1_score</td><td>0.86534</td></tr><tr><td>val_loss</td><td>0.05908</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">likely-sweep-3</strong> at: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/qknm4ro1' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/qknm4ro1</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240228_030538-qknm4ro1\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ot5uz1u3 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.001\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\AI projects\\NER_keras\\wandb\\run-20240228_032500-ot5uz1u3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/ot5uz1u3' target=\"_blank\">different-sweep-4</a></strong> to <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/ot5uz1u3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/ot5uz1u3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-large-uncased-abstract and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate = 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonlc\\AppData\\Local\\Temp\\ipykernel_22768\\3119774215.py:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.08\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.02\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.87\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.83\n",
      "Recall Score: 0.79\n",
      "Precision Score: 0.86\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.87\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.06\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.06\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.06\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.06\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.06\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>precision score</td><td>▃▂▁█▄▆▄▇▅▇▄█▆▇▆▇▇</td></tr><tr><td>recall score</td><td>▄▄▁▅▇▇▇▆▆▇█▇▆▇▇▇▇</td></tr><tr><td>train_batch_loss</td><td>█▆▂▅▂▇▃▆▁▁▂▁▁▂▂▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy_score</td><td>▁▂▁▄██▄▄▄▆▇▅▅▄▆▅▅</td></tr><tr><td>val_f1_score</td><td>▄▄▁▇▇▇▇▇▆▇██▇▇▇▇▇</td></tr><tr><td>val_loss</td><td>▁▁▁▃▂▄▄▅▆▅▅▇▆█▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>16</td></tr><tr><td>precision score</td><td>0.89255</td></tr><tr><td>recall score</td><td>0.85471</td></tr><tr><td>train_batch_loss</td><td>2e-05</td></tr><tr><td>train_loss</td><td>0.00117</td></tr><tr><td>val_accuracy_score</td><td>0.95633</td></tr><tr><td>val_f1_score</td><td>0.87322</td></tr><tr><td>val_loss</td><td>0.05959</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">different-sweep-4</strong> at: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/ot5uz1u3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/ot5uz1u3</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240228_032500-ot5uz1u3\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: j7nfj837 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.001\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\AI projects\\NER_keras\\wandb\\run-20240228_034828-j7nfj837</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/j7nfj837' target=\"_blank\">lunar-sweep-5</a></strong> to <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/j7nfj837' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/j7nfj837</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-large-uncased-abstract and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate = 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonlc\\AppData\\Local\\Temp\\ipykernel_22768\\3119774215.py:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.15\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.92\n",
      "Validation F1 Score: 0.77\n",
      "Recall Score: 0.69\n",
      "Precision Score: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.80\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.80\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.80\n",
      "Precision Score: 0.91\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.90\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>precision score</td><td>▁▃▅█▄▅▆▇▆▇▆▆▆▇▇▆▆</td></tr><tr><td>recall score</td><td>▁▆▅▆▇▇▇▇▇▇████▇██</td></tr><tr><td>train_batch_loss</td><td>█▃▅▃▅▃▁▁▂▃▃▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁</td></tr><tr><td>train_loss</td><td>█▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy_score</td><td>▁▆▆▆▇▇█▇▇▇▇███▇██</td></tr><tr><td>val_f1_score</td><td>▁▅▆▆▇▇▇▇█▇███████</td></tr><tr><td>val_loss</td><td>█▂▂▃▁▂▂▄▄▄▄▄▆▆▆▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>16</td></tr><tr><td>precision score</td><td>0.90119</td></tr><tr><td>recall score</td><td>0.85066</td></tr><tr><td>train_batch_loss</td><td>0.01223</td></tr><tr><td>train_loss</td><td>0.00479</td></tr><tr><td>val_accuracy_score</td><td>0.95604</td></tr><tr><td>val_f1_score</td><td>0.8752</td></tr><tr><td>val_loss</td><td>0.03957</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lunar-sweep-5</strong> at: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/j7nfj837' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/j7nfj837</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240228_034828-j7nfj837\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 54lycc73 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.001\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\AI projects\\NER_keras\\wandb\\run-20240228_041207-54lycc73</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/54lycc73' target=\"_blank\">polar-sweep-6</a></strong> to <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/54lycc73' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/54lycc73</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-large-uncased-abstract and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate = 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonlc\\AppData\\Local\\Temp\\ipykernel_22768\\3119774215.py:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.19\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.06\n",
      "Validation Accuracy: 0.93\n",
      "Validation F1 Score: 0.75\n",
      "Recall Score: 0.72\n",
      "Precision Score: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.05\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.79\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.79\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.02\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.91\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.91\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.87\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.87\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.87\n",
      "Precision Score: 0.90\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>precision score</td><td>▁▇▇▇▇▇▆██▇▇▇▇▆▇▇▇</td></tr><tr><td>recall score</td><td>▁▅▄▆▇▇▇▆▇█▇▇▇████</td></tr><tr><td>train_batch_loss</td><td>█▃▂▂▁▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy_score</td><td>▁▅▅▆▇▇▇▇▇▇███████</td></tr><tr><td>val_f1_score</td><td>▁▆▆▇▇▇▇▇█████████</td></tr><tr><td>val_loss</td><td>█▃▁▁▁▁▂▃▂▂▃▃▃▃▃▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>16</td></tr><tr><td>precision score</td><td>0.89579</td></tr><tr><td>recall score</td><td>0.86541</td></tr><tr><td>train_batch_loss</td><td>0.00013</td></tr><tr><td>train_loss</td><td>0.00565</td></tr><tr><td>val_accuracy_score</td><td>0.95892</td></tr><tr><td>val_f1_score</td><td>0.88034</td></tr><tr><td>val_loss</td><td>0.03674</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">polar-sweep-6</strong> at: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/54lycc73' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/54lycc73</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240228_041207-54lycc73\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: er7lpt1g with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.01\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\AI projects\\NER_keras\\wandb\\run-20240228_043128-er7lpt1g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/er7lpt1g' target=\"_blank\">upbeat-sweep-7</a></strong> to <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/er7lpt1g' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/er7lpt1g</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-large-uncased-abstract and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate = 5e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonlc\\AppData\\Local\\Temp\\ipykernel_22768\\3119774215.py:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.24\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.07\n",
      "Validation Accuracy: 0.88\n",
      "Validation F1 Score: 0.71\n",
      "Recall Score: 0.65\n",
      "Precision Score: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.07\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.92\n",
      "Validation F1 Score: 0.76\n",
      "Recall Score: 0.69\n",
      "Precision Score: 0.86\n",
      "Average training loss: 0.05\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.93\n",
      "Validation F1 Score: 0.79\n",
      "Recall Score: 0.72\n",
      "Precision Score: 0.87\n",
      "Average training loss: 0.04\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.83\n",
      "Recall Score: 0.77\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.82\n",
      "Recall Score: 0.77\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.83\n",
      "Recall Score: 0.78\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.81\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.80\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.80\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.80\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.90\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>precision score</td><td>▁▆▆▇▇█▇█▇████████</td></tr><tr><td>recall score</td><td>▁▂▄▆▆▆▇▇█▇▇██████</td></tr><tr><td>train_batch_loss</td><td>█▃▂▂▂▂▂▂▃▁▂▁▁▂▁▁▁▂▁▁▁▁▂▂▁▂▁▁▁▂▁▁▂▂▁▁▂▁▁▁</td></tr><tr><td>train_loss</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy_score</td><td>▁▅▆▇▇▇▇▇█▇▇██████</td></tr><tr><td>val_f1_score</td><td>▁▄▅▆▆▇▇▇█▇▇██████</td></tr><tr><td>val_loss</td><td>█▄▃▂▂▂▁▂▁▂▂▂▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>16</td></tr><tr><td>precision score</td><td>0.89741</td></tr><tr><td>recall score</td><td>0.82115</td></tr><tr><td>train_batch_loss</td><td>0.00232</td></tr><tr><td>train_loss</td><td>0.01884</td></tr><tr><td>val_accuracy_score</td><td>0.95114</td></tr><tr><td>val_f1_score</td><td>0.85759</td></tr><tr><td>val_loss</td><td>0.03469</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">upbeat-sweep-7</strong> at: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/er7lpt1g' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/er7lpt1g</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240228_043128-er7lpt1g\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: a0xah7zn with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.001\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\AI projects\\NER_keras\\wandb\\run-20240228_050323-a0xah7zn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/a0xah7zn' target=\"_blank\">elated-sweep-8</a></strong> to <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/a0xah7zn' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/a0xah7zn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-large-uncased-abstract and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate = 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonlc\\AppData\\Local\\Temp\\ipykernel_22768\\3119774215.py:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.19\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.77\n",
      "Recall Score: 0.71\n",
      "Precision Score: 0.83\n",
      "Average training loss: 0.04\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.83\n",
      "Recall Score: 0.77\n",
      "Precision Score: 0.91\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.81\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.91\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.87\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.90\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>precision score</td><td>▁█▇▇▇█▇▆▇▇▇▇▇▇▇▇▇</td></tr><tr><td>recall score</td><td>▁▄▅▆▆▇▇██████████</td></tr><tr><td>train_batch_loss</td><td>█▃▂▂▂▂▂▂▂▁▂▂▁▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy_score</td><td>▁▄▆▇▆▇▇█▇█▇██████</td></tr><tr><td>val_f1_score</td><td>▁▅▆▆▇▇▇██████████</td></tr><tr><td>val_loss</td><td>▆▅▁▂▁▂▂▁▄▃▅▅▅▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>16</td></tr><tr><td>precision score</td><td>0.89687</td></tr><tr><td>recall score</td><td>0.86375</td></tr><tr><td>train_batch_loss</td><td>9e-05</td></tr><tr><td>train_loss</td><td>0.00516</td></tr><tr><td>val_accuracy_score</td><td>0.9574</td></tr><tr><td>val_f1_score</td><td>0.88</td></tr><tr><td>val_loss</td><td>0.04204</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">elated-sweep-8</strong> at: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/a0xah7zn' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/a0xah7zn</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240228_050323-a0xah7zn\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: de2s1ld5 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.001\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\AI projects\\NER_keras\\wandb\\run-20240228_052238-de2s1ld5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/de2s1ld5' target=\"_blank\">likely-sweep-9</a></strong> to <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/de2s1ld5' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/de2s1ld5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-large-uncased-abstract and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate = 5e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonlc\\AppData\\Local\\Temp\\ipykernel_22768\\3119774215.py:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.28\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.06\n",
      "Validation Accuracy: 0.90\n",
      "Validation F1 Score: 0.70\n",
      "Recall Score: 0.65\n",
      "Precision Score: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.07\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.93\n",
      "Validation F1 Score: 0.78\n",
      "Recall Score: 0.71\n",
      "Precision Score: 0.85\n",
      "Average training loss: 0.05\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.81\n",
      "Recall Score: 0.76\n",
      "Precision Score: 0.87\n",
      "Average training loss: 0.04\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.82\n",
      "Recall Score: 0.76\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.83\n",
      "Recall Score: 0.77\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.80\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.81\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.89\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>precision score</td><td>▁▆▇▇█▇▇█▇████████</td></tr><tr><td>recall score</td><td>▁▃▅▅▆▇▇▇▇███▇▇███</td></tr><tr><td>train_batch_loss</td><td>█▃▃▃▂▂▂▂▁▂▁▁▂▁▂▂▁▁▂▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂</td></tr><tr><td>train_loss</td><td>█▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy_score</td><td>▁▅▆▆▆▇▇██████████</td></tr><tr><td>val_f1_score</td><td>▁▄▆▆▇▇▇██████████</td></tr><tr><td>val_loss</td><td>█▄▃▄▄▂▁▁▁▁▁▁▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>16</td></tr><tr><td>precision score</td><td>0.89039</td></tr><tr><td>recall score</td><td>0.82533</td></tr><tr><td>train_batch_loss</td><td>0.01208</td></tr><tr><td>train_loss</td><td>0.01865</td></tr><tr><td>val_accuracy_score</td><td>0.95125</td></tr><tr><td>val_f1_score</td><td>0.85662</td></tr><tr><td>val_loss</td><td>0.03317</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">likely-sweep-9</strong> at: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/de2s1ld5' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/de2s1ld5</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240228_052238-de2s1ld5\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: btw98lln with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.01\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\AI projects\\NER_keras\\wandb\\run-20240228_055440-btw98lln</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/btw98lln' target=\"_blank\">rich-sweep-10</a></strong> to <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/btw98lln' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/btw98lln</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-large-uncased-abstract and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate = 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonlc\\AppData\\Local\\Temp\\ipykernel_22768\\3119774215.py:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.17\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.93\n",
      "Validation F1 Score: 0.75\n",
      "Recall Score: 0.69\n",
      "Precision Score: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.05\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.82\n",
      "Recall Score: 0.78\n",
      "Precision Score: 0.87\n",
      "Average training loss: 0.04\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.81\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.91\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>precision score</td><td>▁▅▆▆▇▇▆██▇▇▇▇▇▇▇▇</td></tr><tr><td>recall score</td><td>▁▅▆▇▇▇▇▇▇████████</td></tr><tr><td>train_batch_loss</td><td>█▃▄▄▃▂▂▂▂▂▂▂▁▁▁▂▃▂▂▁▂▂▁▂▁▁▁▂▁▁▁▂▁▁▁▂▂▁▁▁</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy_score</td><td>▁▅▆▇▇▇▇▇▇▇█▇█████</td></tr><tr><td>val_f1_score</td><td>▁▅▇▇▇▇▇▇█████████</td></tr><tr><td>val_loss</td><td>█▄▃▁▂▃▃▂▃▄▄▅▅▅▄▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>16</td></tr><tr><td>precision score</td><td>0.89363</td></tr><tr><td>recall score</td><td>0.84525</td></tr><tr><td>train_batch_loss</td><td>0.02225</td></tr><tr><td>train_loss</td><td>0.01104</td></tr><tr><td>val_accuracy_score</td><td>0.9552</td></tr><tr><td>val_f1_score</td><td>0.86877</td></tr><tr><td>val_loss</td><td>0.03588</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rich-sweep-10</strong> at: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/btw98lln' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/btw98lln</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240228_055440-btw98lln\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qd458b9d with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.001\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\AI projects\\NER_keras\\wandb\\run-20240228_062640-qd458b9d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/qd458b9d' target=\"_blank\">hopeful-sweep-11</a></strong> to <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/qd458b9d' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/qd458b9d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-large-uncased-abstract and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate = 5e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonlc\\AppData\\Local\\Temp\\ipykernel_22768\\3119774215.py:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.37\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.06\n",
      "Validation Accuracy: 0.88\n",
      "Validation F1 Score: 0.66\n",
      "Recall Score: 0.64\n",
      "Precision Score: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.06\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.93\n",
      "Validation F1 Score: 0.75\n",
      "Recall Score: 0.68\n",
      "Precision Score: 0.85\n",
      "Average training loss: 0.04\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.93\n",
      "Validation F1 Score: 0.79\n",
      "Recall Score: 0.72\n",
      "Precision Score: 0.87\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.83\n",
      "Recall Score: 0.78\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.79\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.81\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.83\n",
      "Recall Score: 0.78\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.81\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.80\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.80\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.89\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>precision score</td><td>▁▇▇██████████████</td></tr><tr><td>recall score</td><td>▁▂▄▆▇█▆█▇▇███████</td></tr><tr><td>train_batch_loss</td><td>█▃▃▂▂▁▂▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy_score</td><td>▁▅▆▇▇█▇██▇███████</td></tr><tr><td>val_f1_score</td><td>▁▄▆▇▇█▇██▇███████</td></tr><tr><td>val_loss</td><td>█▄▄▂▁▁▂▁▂▂▁▂▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>16</td></tr><tr><td>precision score</td><td>0.89147</td></tr><tr><td>recall score</td><td>0.8218</td></tr><tr><td>train_batch_loss</td><td>0.01772</td></tr><tr><td>train_loss</td><td>0.01585</td></tr><tr><td>val_accuracy_score</td><td>0.95154</td></tr><tr><td>val_f1_score</td><td>0.85522</td></tr><tr><td>val_loss</td><td>0.03081</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hopeful-sweep-11</strong> at: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/qd458b9d' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/qd458b9d</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240228_062640-qd458b9d\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lnktumxw with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.01\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\AI projects\\NER_keras\\wandb\\run-20240228_064558-lnktumxw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/lnktumxw' target=\"_blank\">eternal-sweep-12</a></strong> to <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/lnktumxw' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/lnktumxw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-large-uncased-abstract and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate = 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonlc\\AppData\\Local\\Temp\\ipykernel_22768\\3119774215.py:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.07\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.81\n",
      "Precision Score: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.02\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.91\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.87\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.87\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.87\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.06\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.06\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>precision score</td><td>▁▇▆█▅▄▄▃▄▅▂▆▂▄▅▅▄</td></tr><tr><td>recall score</td><td>▁▃▅▅▇▆▇▇█▇▇▆██▇▇▇</td></tr><tr><td>train_batch_loss</td><td>█▇█▂▄▄▄▆▄▁▃▂▁▃▁▁▂▁▁▁▁▁▁▁▁▃▁▁▁▁▁▁▁▂▁▁▁▁▁▂</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy_score</td><td>▁▄▇▇▇▆▇▇██▇▇▇███▇</td></tr><tr><td>val_f1_score</td><td>▁▅▆▇█▆▇▇██▆▇▇█▇█▇</td></tr><tr><td>val_loss</td><td>▁▁▁▃▃▄▃▅▅▇▇▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>16</td></tr><tr><td>precision score</td><td>0.89093</td></tr><tr><td>recall score</td><td>0.86117</td></tr><tr><td>train_batch_loss</td><td>1e-05</td></tr><tr><td>train_loss</td><td>0.00124</td></tr><tr><td>val_accuracy_score</td><td>0.95796</td></tr><tr><td>val_f1_score</td><td>0.8758</td></tr><tr><td>val_loss</td><td>0.05523</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">eternal-sweep-12</strong> at: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/lnktumxw' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/lnktumxw</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240228_064558-lnktumxw\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ioqqnm4w with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.01\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\AI projects\\NER_keras\\wandb\\run-20240228_070925-ioqqnm4w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/ioqqnm4w' target=\"_blank\">major-sweep-13</a></strong> to <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/ioqqnm4w' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/ioqqnm4w</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-large-uncased-abstract and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate = 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonlc\\AppData\\Local\\Temp\\ipykernel_22768\\3119774215.py:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.05\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.93\n",
      "Validation F1 Score: 0.82\n",
      "Recall Score: 0.78\n",
      "Precision Score: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.87\n",
      "Precision Score: 0.87\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.87\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.06\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.06\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.06\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.06\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.06\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.06\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>precision score</td><td>▁▇▅▄▄▆▄█▄▅▅▇▅▆▆▆▆</td></tr><tr><td>recall score</td><td>▁▄▇▇▆▇█▇▆▆▇▇▇▇▆▇▇</td></tr><tr><td>train_batch_loss</td><td>▃█▄▂▃▂▂▁▁▁▁▁▁▁▁▁▂▁▁▁▁▃▁▁▁▁▁▁▁▂▄▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▄▃▂▂▂▁▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy_score</td><td>▁▆▇▇▇▇██▆▇▇█▇▇▇▇█</td></tr><tr><td>val_f1_score</td><td>▁▆▇▇▆▇▇█▅▆▇█▇▇▇██</td></tr><tr><td>val_loss</td><td>▂▁▂▂▃▂▄▅▇▆▆▇▇█▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>16</td></tr><tr><td>precision score</td><td>0.89093</td></tr><tr><td>recall score</td><td>0.85893</td></tr><tr><td>train_batch_loss</td><td>0.0</td></tr><tr><td>train_loss</td><td>0.00102</td></tr><tr><td>val_accuracy_score</td><td>0.95683</td></tr><tr><td>val_f1_score</td><td>0.87464</td></tr><tr><td>val_loss</td><td>0.0617</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">major-sweep-13</strong> at: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/ioqqnm4w' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/ioqqnm4w</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240228_070925-ioqqnm4w\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8r6mpdui with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.001\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\AI projects\\NER_keras\\wandb\\run-20240228_074121-8r6mpdui</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/8r6mpdui' target=\"_blank\">vivid-sweep-14</a></strong> to <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/8r6mpdui' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/8r6mpdui</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-large-uncased-abstract and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate = 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonlc\\AppData\\Local\\Temp\\ipykernel_22768\\3119774215.py:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.20\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.93\n",
      "Validation F1 Score: 0.78\n",
      "Recall Score: 0.71\n",
      "Precision Score: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.80\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.81\n",
      "Precision Score: 0.87\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.80\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.80\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>precision score</td><td>▁▅▃▆████▇▇▆██▇▆▇▇</td></tr><tr><td>recall score</td><td>▁▅▆▆▆▇▇▇▇██▇▇████</td></tr><tr><td>train_batch_loss</td><td>█▂▂▂▂▁▁▁▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy_score</td><td>▁▅▇▅▆▇▇▇▇████▇███</td></tr><tr><td>val_f1_score</td><td>▁▅▆▆▆▇▇█▇████████</td></tr><tr><td>val_loss</td><td>█▂▁▄▅▄▅▅▆▅▅▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>16</td></tr><tr><td>precision score</td><td>0.89147</td></tr><tr><td>recall score</td><td>0.84235</td></tr><tr><td>train_batch_loss</td><td>0.00092</td></tr><tr><td>train_loss</td><td>0.00492</td></tr><tr><td>val_accuracy_score</td><td>0.95418</td></tr><tr><td>val_f1_score</td><td>0.86621</td></tr><tr><td>val_loss</td><td>0.03876</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">vivid-sweep-14</strong> at: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/8r6mpdui' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/8r6mpdui</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240228_074121-8r6mpdui\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: oayq0jzb with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.01\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\AI projects\\NER_keras\\wandb\\run-20240228_080043-oayq0jzb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/oayq0jzb' target=\"_blank\">eager-sweep-15</a></strong> to <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/oayq0jzb' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/oayq0jzb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-large-uncased-abstract and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate = 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonlc\\AppData\\Local\\Temp\\ipykernel_22768\\3119774215.py:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.09\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.79\n",
      "Precision Score: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.81\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.06\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.06\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.06\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>precision score</td><td>▇▂█▄██▃▁▃▅▄▂▃▂▃▄▄</td></tr><tr><td>recall score</td><td>▁▃▆▆▆▆▇█▇█▇▇██▇▇▇</td></tr><tr><td>train_batch_loss</td><td>█▂▂▂▃▁▂▇▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▁▁▁▁▁▃</td></tr><tr><td>train_loss</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy_score</td><td>▁▅▇█▇▇▇█▆█▇▇█▇▆▇▇</td></tr><tr><td>val_f1_score</td><td>▁▂▆▆▇▇▇▇▆█▇▇▇▇▇▇▇</td></tr><tr><td>val_loss</td><td>▂▁▁▂▃▄▄▃▆▄▄▆▅▆█▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>16</td></tr><tr><td>precision score</td><td>0.89363</td></tr><tr><td>recall score</td><td>0.85751</td></tr><tr><td>train_batch_loss</td><td>2e-05</td></tr><tr><td>train_loss</td><td>0.0012</td></tr><tr><td>val_accuracy_score</td><td>0.95587</td></tr><tr><td>val_f1_score</td><td>0.8752</td></tr><tr><td>val_loss</td><td>0.05931</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">eager-sweep-15</strong> at: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/oayq0jzb' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/oayq0jzb</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240228_080043-oayq0jzb\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: yo2fxkgb with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.01\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\AI projects\\NER_keras\\wandb\\run-20240228_083235-yo2fxkgb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/yo2fxkgb' target=\"_blank\">ethereal-sweep-16</a></strong> to <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/yo2fxkgb' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/yo2fxkgb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-large-uncased-abstract and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate = 5e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonlc\\AppData\\Local\\Temp\\ipykernel_22768\\3119774215.py:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.25\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.07\n",
      "Validation Accuracy: 0.87\n",
      "Validation F1 Score: 0.67\n",
      "Recall Score: 0.60\n",
      "Precision Score: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.07\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.92\n",
      "Validation F1 Score: 0.74\n",
      "Recall Score: 0.67\n",
      "Precision Score: 0.85\n",
      "Average training loss: 0.05\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.93\n",
      "Validation F1 Score: 0.79\n",
      "Recall Score: 0.73\n",
      "Precision Score: 0.87\n",
      "Average training loss: 0.04\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.82\n",
      "Recall Score: 0.77\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.04\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.83\n",
      "Recall Score: 0.77\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.78\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.80\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.83\n",
      "Recall Score: 0.79\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.79\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.81\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.81\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.81\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.81\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.90\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>precision score</td><td>▁▅▇▇███▇█████████</td></tr><tr><td>recall score</td><td>▁▃▅▆▆▇▇▇▇████████</td></tr><tr><td>train_batch_loss</td><td>█▄▄▂▃▂▂▂▁▁▂▁▂▁▁▄▁▁▁▁▁▃▁▁▁▁▁▃▁▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy_score</td><td>▁▆▆▇▇▇▇▇▇████████</td></tr><tr><td>val_f1_score</td><td>▁▄▆▇▇▇▇▇▇████████</td></tr><tr><td>val_loss</td><td>█▃▃▁▂▂▁▂▂▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>16</td></tr><tr><td>precision score</td><td>0.89525</td></tr><tr><td>recall score</td><td>0.82242</td></tr><tr><td>train_batch_loss</td><td>0.00119</td></tr><tr><td>train_loss</td><td>0.01826</td></tr><tr><td>val_accuracy_score</td><td>0.95148</td></tr><tr><td>val_f1_score</td><td>0.85729</td></tr><tr><td>val_loss</td><td>0.03405</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ethereal-sweep-16</strong> at: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/yo2fxkgb' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/yo2fxkgb</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240228_083235-yo2fxkgb\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2aewht7i with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.01\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\AI projects\\NER_keras\\wandb\\run-20240228_090432-2aewht7i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/2aewht7i' target=\"_blank\">upbeat-sweep-17</a></strong> to <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/2aewht7i' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/2aewht7i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-large-uncased-abstract and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate = 5e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonlc\\AppData\\Local\\Temp\\ipykernel_22768\\3119774215.py:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.24\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.06\n",
      "Validation Accuracy: 0.90\n",
      "Validation F1 Score: 0.69\n",
      "Recall Score: 0.63\n",
      "Precision Score: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.07\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.93\n",
      "Validation F1 Score: 0.75\n",
      "Recall Score: 0.67\n",
      "Precision Score: 0.85\n",
      "Average training loss: 0.05\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.93\n",
      "Validation F1 Score: 0.79\n",
      "Recall Score: 0.72\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.04\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.81\n",
      "Recall Score: 0.76\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.04\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.78\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.80\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.81\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.80\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.80\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.90\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>precision score</td><td>▁▆▇▇██▇██████████</td></tr><tr><td>recall score</td><td>▁▃▄▆▆▇▇▇▇████████</td></tr><tr><td>train_batch_loss</td><td>█▆▂▂▂▂▁▂▆▁▁▁▁▁▁▁▁▅▁▂▂▁▂▁▁▂▂▂▁▁▂▃▁▁▂▁▁▁▁▂</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy_score</td><td>▁▅▅▆▇▇█▇▇████████</td></tr><tr><td>val_f1_score</td><td>▁▄▅▆▇▇█▇█████████</td></tr><tr><td>val_loss</td><td>█▄▄▃▃▂▁▂▂▁▁▁▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>16</td></tr><tr><td>precision score</td><td>0.89741</td></tr><tr><td>recall score</td><td>0.82769</td></tr><tr><td>train_batch_loss</td><td>0.00343</td></tr><tr><td>train_loss</td><td>0.01844</td></tr><tr><td>val_accuracy_score</td><td>0.95165</td></tr><tr><td>val_f1_score</td><td>0.86114</td></tr><tr><td>val_loss</td><td>0.03404</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">upbeat-sweep-17</strong> at: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/2aewht7i' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/2aewht7i</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240228_090432-2aewht7i\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: e2m6h9lo with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.01\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\AI projects\\NER_keras\\wandb\\run-20240228_093648-e2m6h9lo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/e2m6h9lo' target=\"_blank\">legendary-sweep-18</a></strong> to <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/e2m6h9lo' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/e2m6h9lo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-large-uncased-abstract and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate = 5e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonlc\\AppData\\Local\\Temp\\ipykernel_22768\\3119774215.py:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.37\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.13\n",
      "Validation Accuracy: 0.79\n",
      "Validation F1 Score: 0.26\n",
      "Recall Score: 0.24\n",
      "Precision Score: 0.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.10\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.92\n",
      "Validation F1 Score: 0.73\n",
      "Recall Score: 0.68\n",
      "Precision Score: 0.78\n",
      "Average training loss: 0.06\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.92\n",
      "Validation F1 Score: 0.75\n",
      "Recall Score: 0.67\n",
      "Precision Score: 0.85\n",
      "Average training loss: 0.05\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.93\n",
      "Validation F1 Score: 0.76\n",
      "Recall Score: 0.69\n",
      "Precision Score: 0.85\n",
      "Average training loss: 0.04\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.93\n",
      "Validation F1 Score: 0.80\n",
      "Recall Score: 0.74\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.04\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.93\n",
      "Validation F1 Score: 0.80\n",
      "Recall Score: 0.73\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.93\n",
      "Validation F1 Score: 0.81\n",
      "Recall Score: 0.75\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.81\n",
      "Recall Score: 0.76\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.81\n",
      "Recall Score: 0.75\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.79\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.83\n",
      "Recall Score: 0.78\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.80\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.81\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.80\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.80\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.80\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.80\n",
      "Precision Score: 0.89\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>precision score</td><td>▁▇▇██████████████</td></tr><tr><td>recall score</td><td>▁▆▆▇▇▇▇▇▇████████</td></tr><tr><td>train_batch_loss</td><td>█▃▂▂▂▁▂▁▂▁▁▂▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy_score</td><td>▁▇▇▇▇▇▇█▇████████</td></tr><tr><td>val_f1_score</td><td>▁▇▇▇▇▇███████████</td></tr><tr><td>val_loss</td><td>█▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>16</td></tr><tr><td>precision score</td><td>0.88823</td></tr><tr><td>recall score</td><td>0.8001</td></tr><tr><td>train_batch_loss</td><td>0.03212</td></tr><tr><td>train_loss</td><td>0.0236</td></tr><tr><td>val_accuracy_score</td><td>0.94776</td></tr><tr><td>val_f1_score</td><td>0.84186</td></tr><tr><td>val_loss</td><td>0.0336</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">legendary-sweep-18</strong> at: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/e2m6h9lo' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/e2m6h9lo</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240228_093648-e2m6h9lo\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tl2munwo with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.001\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\AI projects\\NER_keras\\wandb\\run-20240228_100031-tl2munwo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/tl2munwo' target=\"_blank\">stilted-sweep-19</a></strong> to <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/tl2munwo' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/tl2munwo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-large-uncased-abstract and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate = 5e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonlc\\AppData\\Local\\Temp\\ipykernel_22768\\3119774215.py:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.12\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.81\n",
      "Recall Score: 0.76\n",
      "Precision Score: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.81\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.87\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>precision score</td><td>▄▅▇█▆▆▅▁█▅▅▇▇▆▇█▇</td></tr><tr><td>recall score</td><td>▁▅▆▆█▇▆▇▆▇▇▇▇▇▇▇▇</td></tr><tr><td>train_batch_loss</td><td>██▄▂▂▂▂▂▂▁▁▁▁▂▃▁▁▁▂▁▁▃▂▁▁▁▁▁▁▂▁▁▁▁▁▂▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy_score</td><td>▁▅▇▆█▇▆▆▅▇▆▅▇▇▆▆▆</td></tr><tr><td>val_f1_score</td><td>▁▅▇▇█▇▆▆▇▇▇▇▇▇▇▇█</td></tr><tr><td>val_loss</td><td>▂▁▂▂▂▄▄▅▅▅▆▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>16</td></tr><tr><td>precision score</td><td>0.89147</td></tr><tr><td>recall score</td><td>0.84537</td></tr><tr><td>train_batch_loss</td><td>3e-05</td></tr><tr><td>train_loss</td><td>0.00206</td></tr><tr><td>val_accuracy_score</td><td>0.95486</td></tr><tr><td>val_f1_score</td><td>0.86781</td></tr><tr><td>val_loss</td><td>0.05084</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">stilted-sweep-19</strong> at: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/tl2munwo' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/tl2munwo</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240228_100031-tl2munwo\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xarayshx with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.01\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\AI projects\\NER_keras\\wandb\\run-20240228_104000-xarayshx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/xarayshx' target=\"_blank\">avid-sweep-20</a></strong> to <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/xarayshx' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/xarayshx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-large-uncased-abstract and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate = 5e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonlc\\AppData\\Local\\Temp\\ipykernel_22768\\3119774215.py:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.27\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.92\n",
      "Validation F1 Score: 0.74\n",
      "Recall Score: 0.68\n",
      "Precision Score: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.05\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.81\n",
      "Recall Score: 0.75\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.83\n",
      "Recall Score: 0.79\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.80\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.80\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.81\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.89\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>precision score</td><td>▁▆▆▇█▇▇▇█▇█▇▇▇▇▇▇</td></tr><tr><td>recall score</td><td>▁▄▆▆▆▇▇█▇▇▇██████</td></tr><tr><td>train_batch_loss</td><td>█▃▂▂▁▁▂▁▁▁▁▂▁▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy_score</td><td>▁▄▆▇▆█▇▇▇▇▇██████</td></tr><tr><td>val_f1_score</td><td>▁▅▆▇▇█▇█▇████████</td></tr><tr><td>val_loss</td><td>█▄▂▁▂▁▂▂▃▂▃▂▃▃▃▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>16</td></tr><tr><td>precision score</td><td>0.89363</td></tr><tr><td>recall score</td><td>0.83208</td></tr><tr><td>train_batch_loss</td><td>0.00065</td></tr><tr><td>train_loss</td><td>0.01094</td></tr><tr><td>val_accuracy_score</td><td>0.95334</td></tr><tr><td>val_f1_score</td><td>0.86175</td></tr><tr><td>val_loss</td><td>0.03331</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">avid-sweep-20</strong> at: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/xarayshx' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/xarayshx</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240228_104000-xarayshx\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ojpyon52 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.01\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\AI projects\\NER_keras\\wandb\\run-20240228_110545-ojpyon52</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/ojpyon52' target=\"_blank\">worldly-sweep-21</a></strong> to <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/ojpyon52' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/ojpyon52</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-large-uncased-abstract and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate = 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonlc\\AppData\\Local\\Temp\\ipykernel_22768\\3119774215.py:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.12\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.83\n",
      "Recall Score: 0.79\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.04\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.91\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.91\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.87\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.88\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.87\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.87\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.87\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.87\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.87\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.87\n",
      "Precision Score: 0.89\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>precision score</td><td>▁▃█▇▂▄▅▃▃▅▄▄▂▂▄▃▂</td></tr><tr><td>recall score</td><td>▁▄▃▄▆▆▅▇█▆█▇▇▇███</td></tr><tr><td>train_batch_loss</td><td>█▃▂▃▁▃▄▂▄▂▃▁▂▁▂▂▁▁▁▃▁▁▁▂▂▁▁▂▁▁▁▁▁▄▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy_score</td><td>▁▄▃▅▇▆▆█▇▆███▇██▇</td></tr><tr><td>val_f1_score</td><td>▁▄▅▅▆▆▆▇█▇██▇▇█▇▇</td></tr><tr><td>val_loss</td><td>▃▃▂▁▂▃▁▂▄▆▅▅▅▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>16</td></tr><tr><td>precision score</td><td>0.88823</td></tr><tr><td>recall score</td><td>0.87083</td></tr><tr><td>train_batch_loss</td><td>8e-05</td></tr><tr><td>train_loss</td><td>0.00392</td></tr><tr><td>val_accuracy_score</td><td>0.95587</td></tr><tr><td>val_f1_score</td><td>0.87944</td></tr><tr><td>val_loss</td><td>0.05287</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">worldly-sweep-21</strong> at: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/ojpyon52' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/ojpyon52</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240228_110545-ojpyon52\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5dcsm540 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.01\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\AI projects\\NER_keras\\wandb\\run-20240228_114539-5dcsm540</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/5dcsm540' target=\"_blank\">leafy-sweep-22</a></strong> to <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/5dcsm540' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/5dcsm540</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-large-uncased-abstract and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate = 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonlc\\AppData\\Local\\Temp\\ipykernel_22768\\3119774215.py:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.09\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.83\n",
      "Recall Score: 0.77\n",
      "Precision Score: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.91\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.87\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.87\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>precision score</td><td>▂██▄▁▆▃▂▄▁▆▂▁▂▁▃▂</td></tr><tr><td>recall score</td><td>▁▄▆▆▇▆▇▇▇█▇██████</td></tr><tr><td>train_batch_loss</td><td>█▆▂▂▂▁▂▁▂▁▂▁▁▁▁▁▁▁▁▁▂▂▂▁▁▂▁▁▁▁▁▂▂▂▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy_score</td><td>▁▄▆▆▇▆▇▇▇█▇█▇▇▆▇▇</td></tr><tr><td>val_f1_score</td><td>▁▅▇▇▇▇█▇▇█▇██████</td></tr><tr><td>val_loss</td><td>▂▁▁▂▁▃▃▄▆▆▆▆▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>16</td></tr><tr><td>precision score</td><td>0.89363</td></tr><tr><td>recall score</td><td>0.86153</td></tr><tr><td>train_batch_loss</td><td>0.00163</td></tr><tr><td>train_loss</td><td>0.00187</td></tr><tr><td>val_accuracy_score</td><td>0.95672</td></tr><tr><td>val_f1_score</td><td>0.87729</td></tr><tr><td>val_loss</td><td>0.05102</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">leafy-sweep-22</strong> at: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/5dcsm540' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/5dcsm540</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240228_114539-5dcsm540\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 54odlmpg with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.01\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\AI projects\\NER_keras\\wandb\\run-20240228_121838-54odlmpg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/54odlmpg' target=\"_blank\">olive-sweep-23</a></strong> to <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/54odlmpg' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/54odlmpg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-large-uncased-abstract and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate = 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonlc\\AppData\\Local\\Temp\\ipykernel_22768\\3119774215.py:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.07\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.83\n",
      "Recall Score: 0.78\n",
      "Precision Score: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.87\n",
      "Precision Score: 0.87\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.87\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.89\n",
      "Recall Score: 0.87\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.87\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.06\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.87\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.06\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.06\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.06\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.07\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.07\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>precision score</td><td>▇▂█▁▅▆▄▆▂▇▄▅▅▆▅▅▅</td></tr><tr><td>recall score</td><td>▁▅▆█▅▆▆▆████▇▇▇▇▇</td></tr><tr><td>train_batch_loss</td><td>▃█▂▄▂▂▂▁▁▁█▄▂▁▂▁▁▁▁▁▁▁▁▁▁▁▂▇▁▁▂▁▁▃▁▁▁▂▁▁</td></tr><tr><td>train_loss</td><td>█▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy_score</td><td>▁▅▇▆▆▆▆▇▇█▇▇▇▇▇▇▇</td></tr><tr><td>val_f1_score</td><td>▁▃▆▆▅▅▅▆▆█▇▇▆▇▇▇▇</td></tr><tr><td>val_loss</td><td>▂▂▁▂▃▃▄▃▄▄▆▆▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>16</td></tr><tr><td>precision score</td><td>0.89039</td></tr><tr><td>recall score</td><td>0.86245</td></tr><tr><td>train_batch_loss</td><td>5e-05</td></tr><tr><td>train_loss</td><td>0.00147</td></tr><tr><td>val_accuracy_score</td><td>0.95514</td></tr><tr><td>val_f1_score</td><td>0.8762</td></tr><tr><td>val_loss</td><td>0.0656</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">olive-sweep-23</strong> at: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/54odlmpg' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/54odlmpg</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240228_121838-54odlmpg\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mysvh32f with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.01\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\AI projects\\NER_keras\\wandb\\run-20240228_125702-mysvh32f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/mysvh32f' target=\"_blank\">vibrant-sweep-24</a></strong> to <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/mysvh32f' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/mysvh32f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-large-uncased-abstract and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate = 5e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonlc\\AppData\\Local\\Temp\\ipykernel_22768\\3119774215.py:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.35\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.87\n",
      "Validation F1 Score: 0.68\n",
      "Recall Score: 0.64\n",
      "Precision Score: 0.72\n",
      "Average training loss: 0.06\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.93\n",
      "Validation F1 Score: 0.75\n",
      "Recall Score: 0.68\n",
      "Precision Score: 0.85\n",
      "Average training loss: 0.04\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.80\n",
      "Recall Score: 0.75\n",
      "Precision Score: 0.87\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.82\n",
      "Recall Score: 0.77\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.83\n",
      "Recall Score: 0.78\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.79\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.80\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.79\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.81\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.81\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.90\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>precision score</td><td>▁▆▇▇█████████████</td></tr><tr><td>recall score</td><td>▁▂▅▆▆▆▇▇▇█▇██████</td></tr><tr><td>train_batch_loss</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy_score</td><td>▁▆▇▇▇▇█▇█████████</td></tr><tr><td>val_f1_score</td><td>▁▄▆▇▇▇▇▇█████████</td></tr><tr><td>val_loss</td><td>█▃▂▂▂▁▁▂▁▁▂▁▁▁▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>16</td></tr><tr><td>precision score</td><td>0.89579</td></tr><tr><td>recall score</td><td>0.82292</td></tr><tr><td>train_batch_loss</td><td>0.00448</td></tr><tr><td>train_loss</td><td>0.01535</td></tr><tr><td>val_accuracy_score</td><td>0.95266</td></tr><tr><td>val_f1_score</td><td>0.85781</td></tr><tr><td>val_loss</td><td>0.0298</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">vibrant-sweep-24</strong> at: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/mysvh32f' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/mysvh32f</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240228_125702-mysvh32f\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: f059768j with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.001\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\AI projects\\NER_keras\\wandb\\run-20240228_131955-f059768j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/f059768j' target=\"_blank\">splendid-sweep-25</a></strong> to <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/f059768j' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/f059768j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-large-uncased-abstract and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate = 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonlc\\AppData\\Local\\Temp\\ipykernel_22768\\3119774215.py:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.17\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.92\n",
      "Validation F1 Score: 0.72\n",
      "Recall Score: 0.63\n",
      "Precision Score: 0.83\n",
      "Average training loss: 0.05\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.81\n",
      "Recall Score: 0.75\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.79\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.79\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.80\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.90\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>precision score</td><td>▁▅▇▇▇▇██▇██▇█▇▇▇▇</td></tr><tr><td>recall score</td><td>▁▅▆▆▆▇▇▇█████████</td></tr><tr><td>train_batch_loss</td><td>█▄▃▄▂▂▂▂▂▁▂▂▁▃▂▁▁▁▃▂▁▁▂▂▁▁▁▄▁▁▁▂▁▁▂▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy_score</td><td>▁▅▆▆▆▇▇▇▇███▇████</td></tr><tr><td>val_f1_score</td><td>▁▅▆▇▇▇▇▇█████████</td></tr><tr><td>val_loss</td><td>█▃▂▂▁▁▂▂▁▂▂▂▃▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>16</td></tr><tr><td>precision score</td><td>0.89687</td></tr><tr><td>recall score</td><td>0.844</td></tr><tr><td>train_batch_loss</td><td>0.00093</td></tr><tr><td>train_loss</td><td>0.0102</td></tr><tr><td>val_accuracy_score</td><td>0.95633</td></tr><tr><td>val_f1_score</td><td>0.86963</td></tr><tr><td>val_loss</td><td>0.03525</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">splendid-sweep-25</strong> at: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/f059768j' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/f059768j</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240228_131955-f059768j\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kst2nvgq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.01\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\AI projects\\NER_keras\\wandb\\run-20240228_135827-kst2nvgq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/kst2nvgq' target=\"_blank\">earnest-sweep-26</a></strong> to <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/kst2nvgq' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/kst2nvgq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-large-uncased-abstract and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate = 5e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonlc\\AppData\\Local\\Temp\\ipykernel_22768\\3119774215.py:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.21\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.93\n",
      "Validation F1 Score: 0.74\n",
      "Recall Score: 0.66\n",
      "Precision Score: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.04\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.83\n",
      "Recall Score: 0.79\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.83\n",
      "Recall Score: 0.78\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.79\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>precision score</td><td>▁▅▇█████▇▇▇▇▇▇█▇▇</td></tr><tr><td>recall score</td><td>▁▆▆▆▇▇█▇▇▇███████</td></tr><tr><td>train_batch_loss</td><td>█▃▃▂▂▁▂▂▁▂▂▂▂▁▁▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy_score</td><td>▁▆▅▆█▇██▇▇█▇█████</td></tr><tr><td>val_f1_score</td><td>▁▆▆▆▇▇██▇▇███████</td></tr><tr><td>val_loss</td><td>█▃▂▃▁▃▂▃▅▄▄▄▅▅▅▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>16</td></tr><tr><td>precision score</td><td>0.89147</td></tr><tr><td>recall score</td><td>0.84192</td></tr><tr><td>train_batch_loss</td><td>0.00119</td></tr><tr><td>train_loss</td><td>0.00634</td></tr><tr><td>val_accuracy_score</td><td>0.95644</td></tr><tr><td>val_f1_score</td><td>0.86598</td></tr><tr><td>val_loss</td><td>0.03516</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">earnest-sweep-26</strong> at: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/kst2nvgq' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/kst2nvgq</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240228_135827-kst2nvgq\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: yc0xmeq6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.001\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\AI projects\\NER_keras\\wandb\\run-20240228_142457-yc0xmeq6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/yc0xmeq6' target=\"_blank\">polar-sweep-27</a></strong> to <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/yc0xmeq6' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/yc0xmeq6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-large-uncased-abstract and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate = 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonlc\\AppData\\Local\\Temp\\ipykernel_22768\\3119774215.py:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.14\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.81\n",
      "Recall Score: 0.78\n",
      "Precision Score: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.79\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.02\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.91\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.91\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.90\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>precision score</td><td>▁▇█▇▇▅█▇█▇▇█▇▇▇▆▇</td></tr><tr><td>recall score</td><td>▁▂▄▆▆▆▆▇▇▆▇▆███▇▇</td></tr><tr><td>train_batch_loss</td><td>█▃▄▂▁▂▁▂▂▁▂▂▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy_score</td><td>▁▂▆▇▇▇▇██▇█▇█▇█▇▇</td></tr><tr><td>val_f1_score</td><td>▁▄▆▇▇▆▇██▇█▇███▇█</td></tr><tr><td>val_loss</td><td>▃▂▂▁▃▃▄▄▅▆▅▇▆▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>16</td></tr><tr><td>precision score</td><td>0.89849</td></tr><tr><td>recall score</td><td>0.85597</td></tr><tr><td>train_batch_loss</td><td>0.0002</td></tr><tr><td>train_loss</td><td>0.00247</td></tr><tr><td>val_accuracy_score</td><td>0.95678</td></tr><tr><td>val_f1_score</td><td>0.87671</td></tr><tr><td>val_loss</td><td>0.04373</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">polar-sweep-27</strong> at: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/yc0xmeq6' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/yc0xmeq6</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240228_142457-yc0xmeq6\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 00s7109l with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.001\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\AI projects\\NER_keras\\wandb\\run-20240228_144935-00s7109l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/00s7109l' target=\"_blank\">neat-sweep-28</a></strong> to <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/00s7109l' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/00s7109l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-large-uncased-abstract and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate = 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonlc\\AppData\\Local\\Temp\\ipykernel_22768\\3119774215.py:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.06\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.02\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.87\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.06\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.06\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.06\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.06\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.06\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>precision score</td><td>▅▇█▂▁▄▄▅▇▂█▃▃▇▄▅▆</td></tr><tr><td>recall score</td><td>▁▃▃▅▆▂▅▆▆█▆▅▇▆▇▇▇</td></tr><tr><td>train_batch_loss</td><td>▃▂▂▂▁▁▂█▁▁▁▁▁▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▄▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy_score</td><td>▁▄▇▆▆▂▆▇▇██▆▆▆▇▇▇</td></tr><tr><td>val_f1_score</td><td>▁▅▅▄▅▁▅▇▇█▇▅▆▇▇██</td></tr><tr><td>val_loss</td><td>▂▂▁▂▂▄▅▅▄▅▆▆█▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>16</td></tr><tr><td>precision score</td><td>0.89417</td></tr><tr><td>recall score</td><td>0.8616</td></tr><tr><td>train_batch_loss</td><td>1e-05</td></tr><tr><td>train_loss</td><td>0.00125</td></tr><tr><td>val_accuracy_score</td><td>0.95638</td></tr><tr><td>val_f1_score</td><td>0.87758</td></tr><tr><td>val_loss</td><td>0.0632</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">neat-sweep-28</strong> at: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/00s7109l' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/00s7109l</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240228_144935-00s7109l\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mm7dthgy with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.001\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\AI projects\\NER_keras\\wandb\\run-20240228_152133-mm7dthgy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/mm7dthgy' target=\"_blank\">dutiful-sweep-29</a></strong> to <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/mm7dthgy' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/mm7dthgy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-large-uncased-abstract and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate = 5e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonlc\\AppData\\Local\\Temp\\ipykernel_22768\\3119774215.py:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.31\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.80\n",
      "Validation F1 Score: 0.41\n",
      "Recall Score: 0.37\n",
      "Precision Score: 0.45\n",
      "Average training loss: 0.09\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.92\n",
      "Validation F1 Score: 0.73\n",
      "Recall Score: 0.65\n",
      "Precision Score: 0.83\n",
      "Average training loss: 0.06\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.93\n",
      "Validation F1 Score: 0.77\n",
      "Recall Score: 0.70\n",
      "Precision Score: 0.85\n",
      "Average training loss: 0.05\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.93\n",
      "Validation F1 Score: 0.80\n",
      "Recall Score: 0.74\n",
      "Precision Score: 0.87\n",
      "Average training loss: 0.04\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.93\n",
      "Validation F1 Score: 0.80\n",
      "Recall Score: 0.73\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.04\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.81\n",
      "Recall Score: 0.76\n",
      "Precision Score: 0.87\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.82\n",
      "Recall Score: 0.78\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.82\n",
      "Recall Score: 0.77\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.83\n",
      "Recall Score: 0.78\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.80\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.83\n",
      "Recall Score: 0.78\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.79\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.79\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.80\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.81\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.80\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.81\n",
      "Precision Score: 0.89\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>precision score</td><td>▁▇▇██████████████</td></tr><tr><td>recall score</td><td>▁▅▆▇▇▇▇▇▇█▇██████</td></tr><tr><td>train_batch_loss</td><td>█▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy_score</td><td>▁▇▇▇▇████████████</td></tr><tr><td>val_f1_score</td><td>▁▆▇▇▇▇███████████</td></tr><tr><td>val_loss</td><td>█▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>16</td></tr><tr><td>precision score</td><td>0.89093</td></tr><tr><td>recall score</td><td>0.80645</td></tr><tr><td>train_batch_loss</td><td>0.00084</td></tr><tr><td>train_loss</td><td>0.02341</td></tr><tr><td>val_accuracy_score</td><td>0.94658</td></tr><tr><td>val_f1_score</td><td>0.84659</td></tr><tr><td>val_loss</td><td>0.03384</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dutiful-sweep-29</strong> at: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/mm7dthgy' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/mm7dthgy</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240228_152133-mm7dthgy\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: h89rojc6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.001\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\AI projects\\NER_keras\\wandb\\run-20240228_154623-h89rojc6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/h89rojc6' target=\"_blank\">twilight-sweep-30</a></strong> to <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/h89rojc6' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/h89rojc6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-large-uncased-abstract and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate = 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonlc\\AppData\\Local\\Temp\\ipykernel_22768\\3119774215.py:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.12\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.80\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.02\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.87\n",
      "Precision Score: 0.90\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>precision score</td><td>█▆▁▃▆▆▇▇█▆▇▇▅▆▇▆▇</td></tr><tr><td>recall score</td><td>▁▃▇▇▇▇▆▇▆█▇▇▇█▇██</td></tr><tr><td>train_batch_loss</td><td>█▄▅▂▂▃▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy_score</td><td>▁▃▇▇█▇▆▇▆█▆▇▇▇▇▇█</td></tr><tr><td>val_f1_score</td><td>▁▃▅▆▇▇▆▇▆██▇▇▇▇▇█</td></tr><tr><td>val_loss</td><td>▂▂▁▁▁▂▄▄▅▅▆▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>16</td></tr><tr><td>precision score</td><td>0.89687</td></tr><tr><td>recall score</td><td>0.86646</td></tr><tr><td>train_batch_loss</td><td>6e-05</td></tr><tr><td>train_loss</td><td>0.00192</td></tr><tr><td>val_accuracy_score</td><td>0.95869</td></tr><tr><td>val_f1_score</td><td>0.8814</td></tr><tr><td>val_loss</td><td>0.04959</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">twilight-sweep-30</strong> at: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/h89rojc6' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/h89rojc6</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240228_154623-h89rojc6\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ptp5gwct with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.001\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\AI projects\\NER_keras\\wandb\\run-20240228_160635-ptp5gwct</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/ptp5gwct' target=\"_blank\">solar-sweep-31</a></strong> to <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/ptp5gwct' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/ptp5gwct</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-large-uncased-abstract and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate = 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonlc\\AppData\\Local\\Temp\\ipykernel_22768\\3119774215.py:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.12\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.83\n",
      "Recall Score: 0.80\n",
      "Precision Score: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.81\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.02\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.90\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>precision score</td><td>▁█▆▄▆▇▇█▇▆▇▇▇▆▆▇▇</td></tr><tr><td>recall score</td><td>▁▂▄▇▆▆▆▇▇▇███▇▇▇█</td></tr><tr><td>train_batch_loss</td><td>█▃▂▂▃▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂</td></tr><tr><td>train_loss</td><td>█▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy_score</td><td>▁▂██▇█▆█▅▄█▇▇█▇▇█</td></tr><tr><td>val_f1_score</td><td>▁▅▅▆▆▇▇█▇▇███▇▇▇█</td></tr><tr><td>val_loss</td><td>▁▂▁▂▂▂▅▅▆▆▅▆▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>16</td></tr><tr><td>precision score</td><td>0.89579</td></tr><tr><td>recall score</td><td>0.85736</td></tr><tr><td>train_batch_loss</td><td>4e-05</td></tr><tr><td>train_loss</td><td>0.00156</td></tr><tr><td>val_accuracy_score</td><td>0.95672</td></tr><tr><td>val_f1_score</td><td>0.87616</td></tr><tr><td>val_loss</td><td>0.04712</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">solar-sweep-31</strong> at: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/ptp5gwct' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/ptp5gwct</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240228_160635-ptp5gwct\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cuhtgpud with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.01\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\AI projects\\NER_keras\\wandb\\run-20240228_163037-cuhtgpud</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/cuhtgpud' target=\"_blank\">fiery-sweep-32</a></strong> to <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/cuhtgpud' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/cuhtgpud</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-large-uncased-abstract and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate = 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonlc\\AppData\\Local\\Temp\\ipykernel_22768\\3119774215.py:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.11\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.83\n",
      "Recall Score: 0.78\n",
      "Precision Score: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.81\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.87\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.87\n",
      "Precision Score: 0.90\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>precision score</td><td>▂▁▄▁▅▆▂▂▅█▇▇▆▄▄▆▅</td></tr><tr><td>recall score</td><td>▁▄▅▇▆▇▇▇▇▇▇▇▇██▇█</td></tr><tr><td>train_batch_loss</td><td>█▂▂▃▂▂▁▃▁▂▁▃▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy_score</td><td>▁▄▆█████▇▇▇▇▇██▇█</td></tr><tr><td>val_f1_score</td><td>▁▃▅▆▆▇▇▇▇▇▇█▇██▇█</td></tr><tr><td>val_loss</td><td>▃▂▂▁▂▃▃▄▄▆▆▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>16</td></tr><tr><td>precision score</td><td>0.89795</td></tr><tr><td>recall score</td><td>0.86569</td></tr><tr><td>train_batch_loss</td><td>0.00035</td></tr><tr><td>train_loss</td><td>0.00298</td></tr><tr><td>val_accuracy_score</td><td>0.95841</td></tr><tr><td>val_f1_score</td><td>0.88153</td></tr><tr><td>val_loss</td><td>0.04829</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fiery-sweep-32</strong> at: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/cuhtgpud' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/cuhtgpud</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240228_163037-cuhtgpud\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 62jojf3g with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.01\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\AI projects\\NER_keras\\wandb\\run-20240228_170735-62jojf3g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/62jojf3g' target=\"_blank\">ancient-sweep-33</a></strong> to <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/62jojf3g' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/62jojf3g</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-large-uncased-abstract and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate = 5e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonlc\\AppData\\Local\\Temp\\ipykernel_22768\\3119774215.py:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.12\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.80\n",
      "Recall Score: 0.75\n",
      "Precision Score: 0.86\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.80\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.80\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>precision score</td><td>▁▆▆▇▇█▇▇▆▇▆▆▇▆▆▆▆</td></tr><tr><td>recall score</td><td>▁▄▄▆▇▇▇▇▇██▇█████</td></tr><tr><td>train_batch_loss</td><td>█▄▂▄▅▂▁▁▂▁▁▄▂▁▁▂▁▁▁▂▁▂▁▁▁▁▁▁▁▁▆▂▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy_score</td><td>▁▅▃▅▇▆▆▆▇█▇▇▇█▇██</td></tr><tr><td>val_f1_score</td><td>▁▅▅▇▇█▇▇▇██▇█████</td></tr><tr><td>val_loss</td><td>▂▁▃▂▂▄▅▆▅▆▆▇███▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>16</td></tr><tr><td>precision score</td><td>0.89417</td></tr><tr><td>recall score</td><td>0.85229</td></tr><tr><td>train_batch_loss</td><td>0.00011</td></tr><tr><td>train_loss</td><td>0.00205</td></tr><tr><td>val_accuracy_score</td><td>0.95717</td></tr><tr><td>val_f1_score</td><td>0.87273</td></tr><tr><td>val_loss</td><td>0.04639</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ancient-sweep-33</strong> at: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/62jojf3g' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/62jojf3g</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240228_170735-62jojf3g\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: x5kq3wdg with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.001\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\AI projects\\NER_keras\\wandb\\run-20240228_175956-x5kq3wdg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/x5kq3wdg' target=\"_blank\">rural-sweep-34</a></strong> to <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/x5kq3wdg' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/x5kq3wdg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-large-uncased-abstract and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate = 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonlc\\AppData\\Local\\Temp\\ipykernel_22768\\3119774215.py:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.22\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.93\n",
      "Validation F1 Score: 0.78\n",
      "Recall Score: 0.71\n",
      "Precision Score: 0.87\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.82\n",
      "Recall Score: 0.75\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.81\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.81\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.90\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>precision score</td><td>▁▇▇█▇▅▇▇▇▆▆▇▇▆▇▇█</td></tr><tr><td>recall score</td><td>▁▃▆▆▇▇█▇█▇▇█▇████</td></tr><tr><td>train_batch_loss</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy_score</td><td>▁▄▇▇▇██▇▇████████</td></tr><tr><td>val_f1_score</td><td>▁▄▆▇▇▇█▇█▇▇█▇████</td></tr><tr><td>val_loss</td><td>█▅▁▃▃▁▂▄▅▆▆▆▆▆█▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>16</td></tr><tr><td>precision score</td><td>0.89579</td></tr><tr><td>recall score</td><td>0.846</td></tr><tr><td>train_batch_loss</td><td>0.00083</td></tr><tr><td>train_loss</td><td>0.00439</td></tr><tr><td>val_accuracy_score</td><td>0.95497</td></tr><tr><td>val_f1_score</td><td>0.87018</td></tr><tr><td>val_loss</td><td>0.03898</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rural-sweep-34</strong> at: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/x5kq3wdg' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/x5kq3wdg</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240228_175956-x5kq3wdg\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fa1ki0mo with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.01\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\AI projects\\NER_keras\\wandb\\run-20240228_182421-fa1ki0mo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/fa1ki0mo' target=\"_blank\">dry-sweep-35</a></strong> to <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/fa1ki0mo' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/fa1ki0mo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-large-uncased-abstract and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate = 5e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonlc\\AppData\\Local\\Temp\\ipykernel_22768\\3119774215.py:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.15\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.79\n",
      "Recall Score: 0.75\n",
      "Precision Score: 0.84\n",
      "Average training loss: 0.04\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.79\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.80\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>precision score</td><td>▁▇█▅▇▇▇▇█▇█▇▇▇▇▇▇</td></tr><tr><td>recall score</td><td>▁▄▄▆▇▇▇▆▇█▇███▇██</td></tr><tr><td>train_batch_loss</td><td>█▃▄▁▁▂▂▂▁▂▂▁▁▁▁▂▂▁▂▂▁▁▁▁▁▁▁▂▁▁▁▂▁▂▁▂▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy_score</td><td>▁▃▅▆▇▇▇▅▇▆▇▇█▇▇██</td></tr><tr><td>val_f1_score</td><td>▁▅▆▆▇▇▇▇█████████</td></tr><tr><td>val_loss</td><td>▆▂▃▁▁▂▂▅▆▆▆▆▆▇█▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>16</td></tr><tr><td>precision score</td><td>0.89039</td></tr><tr><td>recall score</td><td>0.84607</td></tr><tr><td>train_batch_loss</td><td>0.00054</td></tr><tr><td>train_loss</td><td>0.00727</td></tr><tr><td>val_accuracy_score</td><td>0.9543</td></tr><tr><td>val_f1_score</td><td>0.86767</td></tr><tr><td>val_loss</td><td>0.03793</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dry-sweep-35</strong> at: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/fa1ki0mo' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/fa1ki0mo</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240228_182421-fa1ki0mo\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: l8v3uwup with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.001\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\AI projects\\NER_keras\\wandb\\run-20240228_191328-l8v3uwup</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/l8v3uwup' target=\"_blank\">astral-sweep-36</a></strong> to <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/l8v3uwup' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/l8v3uwup</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-large-uncased-abstract and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate = 5e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonlc\\AppData\\Local\\Temp\\ipykernel_22768\\3119774215.py:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.35\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.12\n",
      "Validation Accuracy: 0.82\n",
      "Validation F1 Score: 0.38\n",
      "Recall Score: 0.34\n",
      "Precision Score: 0.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.10\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.92\n",
      "Validation F1 Score: 0.72\n",
      "Recall Score: 0.65\n",
      "Precision Score: 0.82\n",
      "Average training loss: 0.06\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.92\n",
      "Validation F1 Score: 0.74\n",
      "Recall Score: 0.66\n",
      "Precision Score: 0.84\n",
      "Average training loss: 0.05\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.80\n",
      "Recall Score: 0.74\n",
      "Precision Score: 0.87\n",
      "Average training loss: 0.04\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.80\n",
      "Recall Score: 0.75\n",
      "Precision Score: 0.87\n",
      "Average training loss: 0.04\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.93\n",
      "Validation F1 Score: 0.81\n",
      "Recall Score: 0.75\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.81\n",
      "Recall Score: 0.75\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.93\n",
      "Validation F1 Score: 0.82\n",
      "Recall Score: 0.76\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.83\n",
      "Recall Score: 0.79\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.83\n",
      "Recall Score: 0.79\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.79\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.79\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.80\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.80\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.80\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.80\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.80\n",
      "Precision Score: 0.89\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>precision score</td><td>▁▇▇██████████████</td></tr><tr><td>recall score</td><td>▁▆▆▇▇▇▇▇█████████</td></tr><tr><td>train_batch_loss</td><td>█▄▂▃▂▂▁▁▁▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy_score</td><td>▁▇▇▇█▇▇▇█████████</td></tr><tr><td>val_f1_score</td><td>▁▆▆▇▇████████████</td></tr><tr><td>val_loss</td><td>█▂▂▁▁▂▂▂▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>16</td></tr><tr><td>precision score</td><td>0.89039</td></tr><tr><td>recall score</td><td>0.79855</td></tr><tr><td>train_batch_loss</td><td>0.00937</td></tr><tr><td>train_loss</td><td>0.02413</td></tr><tr><td>val_accuracy_score</td><td>0.94489</td></tr><tr><td>val_f1_score</td><td>0.84197</td></tr><tr><td>val_loss</td><td>0.03465</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">astral-sweep-36</strong> at: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/l8v3uwup' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/l8v3uwup</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240228_191328-l8v3uwup\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ydnbx2ac with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.01\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\AI projects\\NER_keras\\wandb\\run-20240228_194021-ydnbx2ac</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/ydnbx2ac' target=\"_blank\">sleek-sweep-37</a></strong> to <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/ydnbx2ac' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/ydnbx2ac</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-large-uncased-abstract and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate = 5e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonlc\\AppData\\Local\\Temp\\ipykernel_22768\\3119774215.py:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.24\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.93\n",
      "Validation F1 Score: 0.73\n",
      "Recall Score: 0.67\n",
      "Precision Score: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.05\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.93\n",
      "Validation F1 Score: 0.80\n",
      "Recall Score: 0.73\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.83\n",
      "Recall Score: 0.78\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.79\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.79\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.81\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.90\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>precision score</td><td>▁▆▇▇▇▇██████▇▇███</td></tr><tr><td>recall score</td><td>▁▄▆▆▆▇███▇███████</td></tr><tr><td>train_batch_loss</td><td>█▃▂▁▁▁▁▁▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy_score</td><td>▁▃▅▆▆▇█▇▇▇▇██████</td></tr><tr><td>val_f1_score</td><td>▁▄▆▇▇▇███████████</td></tr><tr><td>val_loss</td><td>█▆▂▁▂▁▁▂▂▃▃▂▂▁▃▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>16</td></tr><tr><td>precision score</td><td>0.89633</td></tr><tr><td>recall score</td><td>0.83585</td></tr><tr><td>train_batch_loss</td><td>0.01395</td></tr><tr><td>train_loss</td><td>0.01093</td></tr><tr><td>val_accuracy_score</td><td>0.95447</td></tr><tr><td>val_f1_score</td><td>0.86503</td></tr><tr><td>val_loss</td><td>0.0323</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sleek-sweep-37</strong> at: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/ydnbx2ac' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/ydnbx2ac</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240228_194021-ydnbx2ac\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 59e0vlo1 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.01\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\AI projects\\NER_keras\\wandb\\run-20240228_200954-59e0vlo1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/59e0vlo1' target=\"_blank\">brisk-sweep-38</a></strong> to <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/59e0vlo1' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/59e0vlo1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-large-uncased-abstract and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate = 5e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonlc\\AppData\\Local\\Temp\\ipykernel_22768\\3119774215.py:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.23\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.91\n",
      "Validation F1 Score: 0.77\n",
      "Recall Score: 0.73\n",
      "Precision Score: 0.81\n",
      "Average training loss: 0.05\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.79\n",
      "Recall Score: 0.73\n",
      "Precision Score: 0.87\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.83\n",
      "Recall Score: 0.78\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.79\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.80\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.90\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>precision score</td><td>▁▅▇▇████▇▇████▇██</td></tr><tr><td>recall score</td><td>▁▁▄▅▆▆▇▇▇▇█▇▇▇█▇█</td></tr><tr><td>train_batch_loss</td><td>█▃▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁▂▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy_score</td><td>▁▅▆▆▇▇▇██████████</td></tr><tr><td>val_f1_score</td><td>▁▃▆▆▇▇▇██▇███████</td></tr><tr><td>val_loss</td><td>█▄▃▂▂▁▁▁▁▂▂▂▃▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>16</td></tr><tr><td>precision score</td><td>0.89903</td></tr><tr><td>recall score</td><td>0.83333</td></tr><tr><td>train_batch_loss</td><td>0.01825</td></tr><tr><td>train_loss</td><td>0.01088</td></tr><tr><td>val_accuracy_score</td><td>0.95441</td></tr><tr><td>val_f1_score</td><td>0.86494</td></tr><tr><td>val_loss</td><td>0.03197</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">brisk-sweep-38</strong> at: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/59e0vlo1' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/59e0vlo1</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240228_200954-59e0vlo1\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: z90jb7ef with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.001\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\AI projects\\NER_keras\\wandb\\run-20240228_204029-z90jb7ef</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/z90jb7ef' target=\"_blank\">daily-sweep-39</a></strong> to <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/z90jb7ef' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/z90jb7ef</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-large-uncased-abstract and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate = 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonlc\\AppData\\Local\\Temp\\ipykernel_22768\\3119774215.py:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.18\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.81\n",
      "Recall Score: 0.76\n",
      "Precision Score: 0.87\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.83\n",
      "Recall Score: 0.78\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.02\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.87\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>precision score</td><td>▂▆▁▃▆▆▆█▇▅▅▃▆▆▆▆▆</td></tr><tr><td>recall score</td><td>▁▃▇▆█▇▇▆▆▇▇█▇▇▇▇▇</td></tr><tr><td>train_batch_loss</td><td>█▂▁▂▁▂▁▁▁▁▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy_score</td><td>▁▃█▇██▇▆▆▇▇█▇▇▆▇▇</td></tr><tr><td>val_f1_score</td><td>▁▄▆▆█▇▇█▇██▇█████</td></tr><tr><td>val_loss</td><td>▄▃▁▂▂▂▄▅▆▅▆▅▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>16</td></tr><tr><td>precision score</td><td>0.89309</td></tr><tr><td>recall score</td><td>0.84345</td></tr><tr><td>train_batch_loss</td><td>0.00054</td></tr><tr><td>train_loss</td><td>0.00244</td></tr><tr><td>val_accuracy_score</td><td>0.95424</td></tr><tr><td>val_f1_score</td><td>0.86756</td></tr><tr><td>val_loss</td><td>0.04218</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">daily-sweep-39</strong> at: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/z90jb7ef' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/z90jb7ef</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240228_204029-z90jb7ef\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kaoczlws with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.001\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\AI projects\\NER_keras\\wandb\\run-20240228_210317-kaoczlws</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/kaoczlws' target=\"_blank\">solar-sweep-40</a></strong> to <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/kaoczlws' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/kaoczlws</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-large-uncased-abstract and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate = 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonlc\\AppData\\Local\\Temp\\ipykernel_22768\\3119774215.py:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.08\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.81\n",
      "Precision Score: 0.87\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.87\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.06\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.06\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.87\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.06\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>precision score</td><td>▁█▇▃█▆▇▆▇▆▆▅▄▆▇▆▇</td></tr><tr><td>recall score</td><td>▁▁▆█▆▅▆▆▅▅▆▇▇▆▇█▇</td></tr><tr><td>train_batch_loss</td><td>▄▃▂▂▃▂█▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy_score</td><td>▁▄▆█▆█▆▅▇▄▅▆▆▆▆█▇</td></tr><tr><td>val_f1_score</td><td>▁▄▇▇█▆▇▇▇▆▇▇▇▇███</td></tr><tr><td>val_loss</td><td>▁▁▁▁▂▃▅▄▅▆▅▆▆▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>16</td></tr><tr><td>precision score</td><td>0.89417</td></tr><tr><td>recall score</td><td>0.8625</td></tr><tr><td>train_batch_loss</td><td>4e-05</td></tr><tr><td>train_loss</td><td>0.00146</td></tr><tr><td>val_accuracy_score</td><td>0.95768</td></tr><tr><td>val_f1_score</td><td>0.87805</td></tr><tr><td>val_loss</td><td>0.06052</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">solar-sweep-40</strong> at: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/kaoczlws' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/kaoczlws</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240228_210317-kaoczlws\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bd6n0p2j with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.01\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\AI projects\\NER_keras\\wandb\\run-20240228_213220-bd6n0p2j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/bd6n0p2j' target=\"_blank\">fast-sweep-41</a></strong> to <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/bd6n0p2j' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/bd6n0p2j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-large-uncased-abstract and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate = 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonlc\\AppData\\Local\\Temp\\ipykernel_22768\\3119774215.py:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.07\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.02\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.87\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.87\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.87\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.06\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.87\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.87\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.06\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.87\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.06\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.87\n",
      "Precision Score: 0.89\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>precision score</td><td>▆▁▃▆█▅▅█▆█▇▆▆▆▆▇▆</td></tr><tr><td>recall score</td><td>▁▇▆▄▇▆▅▅█▆▇█▇██▇▇</td></tr><tr><td>train_batch_loss</td><td>█▄▅▅▄▆▃▂▄▂▂▂▁▂▅▄▁▁▃▂▁▁▂▁▃▁▁▁▂▁▂▃▁▁▂▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy_score</td><td>▁▆▆▄█▆▅▆█▇▇█▆▆▇▇▇</td></tr><tr><td>val_f1_score</td><td>▁▄▄▄█▆▅▆█▇▇▇▇███▇</td></tr><tr><td>val_loss</td><td>▂▁▁▃▂▃▄▅▅▅▆▇▇█▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>16</td></tr><tr><td>precision score</td><td>0.89471</td></tr><tr><td>recall score</td><td>0.86573</td></tr><tr><td>train_batch_loss</td><td>2e-05</td></tr><tr><td>train_loss</td><td>0.00119</td></tr><tr><td>val_accuracy_score</td><td>0.95807</td></tr><tr><td>val_f1_score</td><td>0.87998</td></tr><tr><td>val_loss</td><td>0.05574</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fast-sweep-41</strong> at: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/bd6n0p2j' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/bd6n0p2j</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240228_213220-bd6n0p2j\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: veurrx25 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.01\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\AI projects\\NER_keras\\wandb\\run-20240228_220032-veurrx25</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/veurrx25' target=\"_blank\">ethereal-sweep-42</a></strong> to <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/veurrx25' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/veurrx25</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-large-uncased-abstract and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate = 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonlc\\AppData\\Local\\Temp\\ipykernel_22768\\3119774215.py:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.24\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.92\n",
      "Validation F1 Score: 0.72\n",
      "Recall Score: 0.67\n",
      "Precision Score: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.06\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.93\n",
      "Validation F1 Score: 0.78\n",
      "Recall Score: 0.71\n",
      "Precision Score: 0.87\n",
      "Average training loss: 0.04\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.93\n",
      "Validation F1 Score: 0.80\n",
      "Recall Score: 0.74\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.80\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.81\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.81\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.81\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.90\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>precision score</td><td>▁▆▇▇▇▇▇██████████</td></tr><tr><td>recall score</td><td>▁▃▄▆▆▇▇▆▇▇█▇█████</td></tr><tr><td>train_batch_loss</td><td>█▄▃▂▂▂▂▂▁▁▁▁▁▂▁▁▁▂▁▂▂▁▁▁▂▂▁▁▁▁▁▁▁▁▁▂▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy_score</td><td>▁▃▃▆▆▇▇▆█████████</td></tr><tr><td>val_f1_score</td><td>▁▄▅▇▇▇▇▇█████████</td></tr><tr><td>val_loss</td><td>█▆▆▃▂▁▁▃▂▂▂▂▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>16</td></tr><tr><td>precision score</td><td>0.89579</td></tr><tr><td>recall score</td><td>0.84729</td></tr><tr><td>train_batch_loss</td><td>0.00178</td></tr><tr><td>train_loss</td><td>0.01437</td></tr><tr><td>val_accuracy_score</td><td>0.95452</td></tr><tr><td>val_f1_score</td><td>0.87087</td></tr><tr><td>val_loss</td><td>0.03178</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ethereal-sweep-42</strong> at: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/veurrx25' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/veurrx25</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240228_220032-veurrx25\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: asym36cw with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.001\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\AI projects\\NER_keras\\wandb\\run-20240228_222617-asym36cw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/asym36cw' target=\"_blank\">exalted-sweep-43</a></strong> to <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/asym36cw' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/asym36cw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-large-uncased-abstract and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate = 5e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonlc\\AppData\\Local\\Temp\\ipykernel_22768\\3119774215.py:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.30\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.91\n",
      "Validation F1 Score: 0.69\n",
      "Recall Score: 0.63\n",
      "Precision Score: 0.76"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average training loss: 0.05\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.93\n",
      "Validation F1 Score: 0.76\n",
      "Recall Score: 0.68\n",
      "Precision Score: 0.87\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.93\n",
      "Validation F1 Score: 0.80\n",
      "Recall Score: 0.73\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.83\n",
      "Recall Score: 0.77\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.81\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.80\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.90\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>precision score</td><td>▁▆▇█▇████████████</td></tr><tr><td>recall score</td><td>▁▃▄▆▇▇▇▇███▇█████</td></tr><tr><td>train_batch_loss</td><td>█▂▁▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy_score</td><td>▁▃▄▆▇▇▇▇█████████</td></tr><tr><td>val_f1_score</td><td>▁▄▅▆▇▇█▇█████████</td></tr><tr><td>val_loss</td><td>█▆▅▂▁▁▂▂▁▂▁▂▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>16</td></tr><tr><td>precision score</td><td>0.89687</td></tr><tr><td>recall score</td><td>0.833</td></tr><tr><td>train_batch_loss</td><td>0.01666</td></tr><tr><td>train_loss</td><td>0.01064</td></tr><tr><td>val_accuracy_score</td><td>0.95531</td></tr><tr><td>val_f1_score</td><td>0.86375</td></tr><tr><td>val_loss</td><td>0.03166</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">exalted-sweep-43</strong> at: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/asym36cw' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/asym36cw</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240228_222617-asym36cw\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 28o8bewx with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.01\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\AI projects\\NER_keras\\wandb\\run-20240228_224628-28o8bewx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/28o8bewx' target=\"_blank\">zany-sweep-44</a></strong> to <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/28o8bewx' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/28o8bewx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-large-uncased-abstract and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate = 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonlc\\AppData\\Local\\Temp\\ipykernel_22768\\3119774215.py:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.10\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.83"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recall Score: 0.78\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.81\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.80\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.87\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.06\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.06\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.06\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.06\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>precision score</td><td>▃▆▇█▁▃▆▅▄▇▇▅▆▇▆▆▆</td></tr><tr><td>recall score</td><td>▁▄▃▅██▇▇▇▆▇██▇▇█▇</td></tr><tr><td>train_batch_loss</td><td>█▄▁▃▂▂▁▂▁▁▂▁▁▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy_score</td><td>▁▄▃▆███▆▆▅█▇█▇▇▇▇</td></tr><tr><td>val_f1_score</td><td>▁▄▄▆▇▇▇▇▆▆████▇█▇</td></tr><tr><td>val_loss</td><td>▁▁▂▂▃▂▅▄▅▅▅▆▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>16</td></tr><tr><td>precision score</td><td>0.89471</td></tr><tr><td>recall score</td><td>0.84757</td></tr><tr><td>train_batch_loss</td><td>4e-05</td></tr><tr><td>train_loss</td><td>0.00103</td></tr><tr><td>val_accuracy_score</td><td>0.95548</td></tr><tr><td>val_f1_score</td><td>0.8705</td></tr><tr><td>val_loss</td><td>0.05832</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">zany-sweep-44</strong> at: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/28o8bewx' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/28o8bewx</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240228_224628-28o8bewx\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bjaxm4xs with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.01\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\AI projects\\NER_keras\\wandb\\run-20240228_230624-bjaxm4xs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/bjaxm4xs' target=\"_blank\">polished-sweep-45</a></strong> to <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/bjaxm4xs' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/bjaxm4xs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-large-uncased-abstract and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate = 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonlc\\AppData\\Local\\Temp\\ipykernel_22768\\3119774215.py:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.10\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.81\n",
      "Precision Score: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.81\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.87\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.87\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.87\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.87\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.87\n",
      "Precision Score: 0.90\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>precision score</td><td>▇▂▇▃▃▃▄█▁▆▆▅▃▅▅▅▆</td></tr><tr><td>recall score</td><td>▁▁▅▆▅▆█▆█▆▇▇███▇█</td></tr><tr><td>train_batch_loss</td><td>█▆▂▁▄▂▁▁▃▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▂▁▃▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy_score</td><td>▁▅▆█▆▆▇▇▆▆▇▇█▇▇▆▇</td></tr><tr><td>val_f1_score</td><td>▃▁▆▆▅▆█▇▆▆█▇▇██▇█</td></tr><tr><td>val_loss</td><td>▂▁▁▂▃▄▄▄▅▆▆▇▅▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>16</td></tr><tr><td>precision score</td><td>0.89687</td></tr><tr><td>recall score</td><td>0.86646</td></tr><tr><td>train_batch_loss</td><td>0.00263</td></tr><tr><td>train_loss</td><td>0.0017</td></tr><tr><td>val_accuracy_score</td><td>0.95757</td></tr><tr><td>val_f1_score</td><td>0.8814</td></tr><tr><td>val_loss</td><td>0.05068</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">polished-sweep-45</strong> at: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/bjaxm4xs' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/bjaxm4xs</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240228_230624-bjaxm4xs\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8djagsb1 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 5e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.01\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\AI projects\\NER_keras\\wandb\\run-20240228_234730-8djagsb1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/8djagsb1' target=\"_blank\">efficient-sweep-46</a></strong> to <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/8djagsb1' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/8djagsb1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-large-uncased-abstract and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate = 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonlc\\AppData\\Local\\Temp\\ipykernel_22768\\3119774215.py:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.07\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.93\n",
      "Validation F1 Score: 0.77\n",
      "Recall Score: 0.73\n",
      "Precision Score: 0.83\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.81\n",
      "Precision Score: 0.87\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.87\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.87\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.91\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.06\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.06\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.06\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.06\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.06\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.06\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.90\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>precision score</td><td>▁▄▇▅▄█▇▇▆▆▇▇▇▇▇▇▇</td></tr><tr><td>recall score</td><td>▁▅▆▇▇▆▇▆█▇▇▇█▇▇▇█</td></tr><tr><td>train_batch_loss</td><td>█▅▃▂▃▁▅▂▁▂▂▁▁▂▁▁▁▂▁▃▁▁▁▁▁▁▁▁▁▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy_score</td><td>▁▆▇▇▇▇▇▆█▇█▇█▇▇█▇</td></tr><tr><td>val_f1_score</td><td>▁▅▇▇▇▇▇▇█▇█▇██▇██</td></tr><tr><td>val_loss</td><td>▃▁▁▂▂▄▄▆▅▇▇█▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>16</td></tr><tr><td>precision score</td><td>0.89579</td></tr><tr><td>recall score</td><td>0.8556</td></tr><tr><td>train_batch_loss</td><td>1e-05</td></tr><tr><td>train_loss</td><td>0.00105</td></tr><tr><td>val_accuracy_score</td><td>0.9561</td></tr><tr><td>val_f1_score</td><td>0.87523</td></tr><tr><td>val_loss</td><td>0.05795</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">efficient-sweep-46</strong> at: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/8djagsb1' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/8djagsb1</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240228_234730-8djagsb1\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: t27ik4r9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.01\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\AI projects\\NER_keras\\wandb\\run-20240229_001222-t27ik4r9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/t27ik4r9' target=\"_blank\">devout-sweep-47</a></strong> to <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/t27ik4r9' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/t27ik4r9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-large-uncased-abstract and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate = 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonlc\\AppData\\Local\\Temp\\ipykernel_22768\\3119774215.py:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.18\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.94\n",
      "Validation F1 Score: 0.78\n",
      "Recall Score: 0.72\n",
      "Precision Score: 0.85\n",
      "Average training loss: 0.03\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.79\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.81\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.89\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇█████</td></tr><tr><td>precision score</td><td>▁▆▅▆▇█▇█▆▇▆█▇▇▆▇▇</td></tr><tr><td>recall score</td><td>▁▅▇▇▆▇███████████</td></tr><tr><td>train_batch_loss</td><td>█▃▂▂▁▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy_score</td><td>▁▆▇█▇████████▇███</td></tr><tr><td>val_f1_score</td><td>▁▆▇▇▇█████████▇██</td></tr><tr><td>val_loss</td><td>▄▁▁▂▃▃▃▄▅▅▅▇▇█▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>16</td></tr><tr><td>precision score</td><td>0.89147</td></tr><tr><td>recall score</td><td>0.84106</td></tr><tr><td>train_batch_loss</td><td>0.00438</td></tr><tr><td>train_loss</td><td>0.00248</td></tr><tr><td>val_accuracy_score</td><td>0.95441</td></tr><tr><td>val_f1_score</td><td>0.86553</td></tr><tr><td>val_loss</td><td>0.04364</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">devout-sweep-47</strong> at: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/t27ik4r9' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/t27ik4r9</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240229_001222-t27ik4r9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bvf8vj59 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 17\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.01\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\AI projects\\NER_keras\\wandb\\run-20240229_003209-bvf8vj59</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/bvf8vj59' target=\"_blank\">comic-sweep-48</a></strong> to <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/sweeps/zcsnbat3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/bvf8vj59' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/bvf8vj59</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-large-uncased-abstract and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate = 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonlc\\AppData\\Local\\Temp\\ipykernel_22768\\3119774215.py:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.09\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.84\n",
      "Recall Score: 0.78\n",
      "Precision Score: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonlc\\anaconda3\\envs\\kerasenv\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.02\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.85\n",
      "Recall Score: 0.82\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.02\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.88\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.03\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.86\n",
      "Recall Score: 0.83\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.88\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.84\n",
      "Precision Score: 0.90\n",
      "Average training loss: 0.01\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.95\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.85\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.04\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n",
      "Average training loss: 0.00\n",
      "\n",
      "Running Validation...\n",
      "Validation loss: 0.05\n",
      "Validation Accuracy: 0.96\n",
      "Validation F1 Score: 0.87\n",
      "Recall Score: 0.86\n",
      "Precision Score: 0.89\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▄▄▄▅▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇████</td></tr><tr><td>precision score</td><td>█▁▂▅▆██▆▅▄▄</td></tr><tr><td>recall score</td><td>▁▅▆▇▆▇▆▇▇▇█</td></tr><tr><td>train_batch_loss</td><td>▆█▆▅▂▆▃▂▃▂▃▄▁▂▃▃▁▁▄▂▂▄█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▁▁▁▁▁▁</td></tr><tr><td>val_accuracy_score</td><td>▁▆▅█▆█▆▆▆▇▇</td></tr><tr><td>val_f1_score</td><td>▁▃▅▇▅█▇▇▇▇█</td></tr><tr><td>val_loss</td><td>▃▁▂▃▄▄▅▆▇▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>precision score</td><td>0.88877</td></tr><tr><td>recall score</td><td>0.86088</td></tr><tr><td>train_batch_loss</td><td>5e-05</td></tr><tr><td>train_loss</td><td>0.00314</td></tr><tr><td>val_accuracy_score</td><td>0.95604</td></tr><tr><td>val_f1_score</td><td>0.8746</td></tr><tr><td>val_loss</td><td>0.04744</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">comic-sweep-48</strong> at: <a href='https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/bvf8vj59' target=\"_blank\">https://wandb.ai/jon-l-collins/NER_ADE_corpus_output3_microsoftBiomedNLP-BiomedBERT-large-uncased-abstract_2024-02-28/runs/bvf8vj59</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240229_003209-bvf8vj59\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.agent(sweep_id, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_sentences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[104], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tokenized_sentence \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mencode(\u001b[43mtest_sentences\u001b[49m[\u001b[38;5;241m11\u001b[39m])\n\u001b[0;32m      2\u001b[0m input_ids_test \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([tokenized_sentence])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_sentences' is not defined"
     ]
    }
   ],
   "source": [
    "tokenized_sentence = tokenizer.encode(test_sentences[11])\n",
    "input_ids_test = torch.tensor([tokenized_sentence]).to(device)\n",
    "with torch.no_grad():\n",
    "    output = model(input_ids_test)\n",
    "label_indices = np.argmax(output[0].to('cpu').numpy(), axis=2)\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids_test.to('cpu').numpy()[0])\n",
    "new_tokens, new_labels = [], []\n",
    "for token, idx in zip(tokens, label_indices[0]):\n",
    "    if token.startswith(\"##\"):\n",
    "        new_tokens[-1] = new_tokens[-1] + token[2:]\n",
    "    else:\n",
    "        new_labels.append(tag_values[idx])\n",
    "        new_tokens.append(token)\n",
    "new_labels = new_labels[1:-1]\n",
    "print(new_labels)\n",
    "print(test_labels[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'B-drug', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'B-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'B-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-drug', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-effect', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'B-effect', 'I-effect', 'O', 'B-drug', 'I-drug', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'I-drug', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-effect', 'I-effect', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'I-drug', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'B-drug', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'B-effect', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'B-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'B-drug', 'I-drug', 'I-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'B-effect', 'O']\n",
      "Predicted labels: ['O', 'B-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'B-effect', 'I-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'O', 'I-effect', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-effect', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O']\n",
      "Actual labels: ['B-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'I-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'I-effect', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-effect', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'I-effect', 'O', 'B-drug', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'I-effect', 'O', 'B-drug', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'I-effect', 'I-effect', 'I-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-effect', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'B-effect', 'I-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'I-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'B-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-effect', 'O', 'B-effect', 'I-effect', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'B-drug', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'I-effect', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'I-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'B-effect', 'I-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'B-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Actual labels: ['B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-effect', 'I-effect', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'I-effect', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'I-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-drug', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-effect', 'I-effect', 'B-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'B-effect', 'I-effect', 'O', 'B-effect', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'B-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'B-drug', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'I-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'B-drug', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'B-effect', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'B-effect', 'O', 'O', 'B-drug', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'B-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Actual labels: ['B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'B-drug', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'B-drug', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-drug', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-drug', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'B-effect', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'B-effect', 'O', 'B-effect', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O']\n",
      "Predicted labels: ['B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'I-effect', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'I-drug', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-effect', 'I-effect', 'O', 'O', 'B-drug', 'I-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'O', 'B-drug', 'I-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Predicted labels: ['O', 'I-effect', 'I-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'B-effect', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['B-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-drug', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'B-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'B-effect', 'I-effect', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-drug', 'I-effect', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-drug', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'B-drug', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Actual labels: ['O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'I-drug', 'I-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'B-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'B-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'B-drug', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'B-drug', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'B-drug', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'I-effect', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'B-drug', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'I-drug', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Predicted labels: ['B-drug', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'B-drug', 'O', 'B-drug', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'B-effect', 'O', 'B-drug', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'B-drug', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['B-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'I-drug', 'O', 'O', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'I-drug', 'B-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'I-effect', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-drug']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'B-effect', 'I-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Actual labels: ['B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'B-drug', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O']\n",
      "Actual labels: ['O', 'B-drug', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'I-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'B-effect', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'B-drug', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-drug', 'I-drug', 'I-effect', 'B-effect', 'O', 'B-drug', 'I-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'B-effect', 'I-effect', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'B-drug', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-effect', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['B-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['B-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-effect', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-effect', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'I-drug', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'B-effect', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['B-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'I-drug', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Actual labels: ['B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'B-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'B-effect', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'B-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'B-effect', 'I-effect', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Actual labels: ['O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'B-drug', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'B-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'B-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-effect', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'B-effect', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'B-drug', 'I-drug', 'I-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'I-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'B-effect', 'O', 'B-effect', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'I-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'B-effect', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'B-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-effect', 'O', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'B-effect', 'I-effect', 'O']\n",
      "Actual labels: ['O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'I-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['B-drug', 'I-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'I-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'B-effect', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'B-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'B-drug', 'B-effect', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['I-effect', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'B-effect', 'I-effect', 'O', 'B-effect', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'B-drug', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-effect', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'I-drug', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-effect', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-effect', 'O', 'B-effect', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'B-effect', 'I-effect', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-effect', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['B-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'B-effect', 'I-effect', 'O', 'B-drug', 'I-drug', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'I-drug', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['B-drug', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'B-effect', 'I-effect', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Predicted labels: ['B-effect', 'I-effect', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'O', 'I-effect', 'I-effect', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'O', 'O', 'B-drug', 'I-drug', 'I-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'B-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'B-drug', 'I-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'B-effect', 'B-effect', 'O', 'B-effect', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'B-effect', 'I-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'B-drug', 'O', 'O', 'O', 'B-effect', 'O', 'I-effect', 'B-effect', 'I-effect', 'I-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-drug', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Actual labels: ['B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'O', 'B-effect', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['B-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'I-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'I-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'B-drug', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'B-effect', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'B-effect', 'B-effect', 'I-effect', 'O', 'O', 'O', 'B-drug', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'I-drug', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'B-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'B-drug', 'I-drug', 'I-drug', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'I-drug', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['B-effect', 'I-effect', 'I-effect', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'B-effect', 'I-effect', 'I-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'I-effect', 'O', 'B-drug', 'I-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'B-drug', 'I-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'B-effect', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'B-effect', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'B-drug', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-effect', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'B-drug', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O']\n",
      "Predicted labels: ['B-drug', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-effect', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'I-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'I-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'B-effect', 'I-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'I-effect', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'I-drug', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-effect', 'O', 'O', 'B-effect', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-effect', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'B-effect', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'I-effect', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Actual labels: ['B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'B-drug', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'I-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'B-drug', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-effect', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'I-drug', 'I-drug', 'I-drug', 'I-drug', 'I-drug', 'I-drug', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['I-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['B-drug', 'I-effect', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'B-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-drug', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'B-drug', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-drug', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'I-drug', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'I-drug', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-drug', 'B-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-drug', 'I-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-drug', 'I-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-effect', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'I-drug', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'B-effect', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'B-effect', 'O', 'B-drug', 'I-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'B-drug', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-drug', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'I-drug', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['B-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-effect', 'I-effect', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'B-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-drug', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-effect', 'B-effect', 'O', 'B-drug', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'B-effect', 'O', 'B-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'B-effect', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'B-effect', 'B-effect', 'I-effect', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'B-effect', 'I-effect', 'O', 'B-drug', 'I-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-drug', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'B-effect', 'I-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['B-drug', 'I-drug', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'I-drug', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'B-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'B-drug', 'I-effect', 'I-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'B-effect', 'I-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'I-effect', 'I-effect', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'B-drug', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'B-effect', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'B-drug', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'I-drug', 'O', 'O', 'B-effect', 'O']\n",
      "Actual labels: ['B-drug', 'I-drug', 'O', 'O', 'B-effect', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'B-drug', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O']\n",
      "Predicted labels: ['B-drug', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'B-drug', 'I-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['B-drug', 'O', 'O', 'B-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'B-drug', 'I-drug', 'O', 'O', 'B-drug', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-effect', 'I-effect', 'I-effect', 'I-effect', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'O', 'O']\n",
      "Predicted labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Actual labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-drug', 'O', 'O', 'B-effect', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "----------Done------------\n",
      "Test Accuracy 0.8647317051303433\n"
     ]
    }
   ],
   "source": [
    "accuracy_list = []\n",
    "\n",
    "for i in range(len(test_sentences)):\n",
    "    tokenized_sentence = tokenizer.encode(test_sentences[i])\n",
    "    input_ids_test = torch.tensor([tokenized_sentence]).to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids_test)\n",
    "    label_indices = np.argmax(output[0].to('cpu').numpy(), axis=2)\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids_test.to('cpu').numpy()[0])\n",
    "    new_tokens, new_labels = [], []\n",
    "    for token, idx in zip(tokens, label_indices[0]):\n",
    "        if token.startswith(\"##\"):\n",
    "            new_tokens[-1] = new_tokens[-1] + token[2:]\n",
    "        else:\n",
    "            new_labels.append(tag_values[idx])\n",
    "            new_tokens.append(token)\n",
    "    new_labels = new_labels[1:-1]\n",
    "    accuracy_list.append(accuracy_score(new_labels,test_labels[i]))\n",
    "    print(\"Predicted labels:\",new_labels)\n",
    "    print(\"Actual labels:\",test_labels[i])\n",
    "    \n",
    "print(\"\\n----------Done------------\")\n",
    "print(\"Test Accuracy\",statistics.mean(accuracy_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bestpytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
