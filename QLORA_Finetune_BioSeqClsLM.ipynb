{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "mMbxRe5e4H3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers trl peft huggingface_hub datasets bitsandbytes accelerate"
      ],
      "metadata": {
        "id": "0dtaGZTyTZbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasetname = \"collij22/adesplit\"\n",
        "#datasetname = \"collij22/jcpsytar\"\n",
        "\n",
        "#model_id=\"microsoft/BioGPT-Large-PubMedQA\"\n",
        "#model_id = \"BioMistral/BioMistral-7B\"\n",
        "#model_id = \"stanford-crfm/BioMedLM\"\n",
        "#model_id = \"PharMolix/BioMedGPT-LM-7B\"\n",
        "\n",
        "model_id = \"facebook/opt-2.7b\"\n",
        "#model_id = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
        "\n",
        "\n",
        "#model_id = \"mistralai/Mixtral-8x7B-v0.1\"\n",
        "#model_id = \"meta-llama/Llama-2-7b-chat-hf\"\n",
        "\n",
        "epoch=5\n",
        "learning_rate = 3e-4"
      ],
      "metadata": {
        "id": "K4czeUcKTXQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if model_id == \"microsoft/BioGPT-Large-PubMedQA\":\n",
        "  specific_modules = [\"q_proj\",\"v_proj\",\"k_proj\",\"out_proj\"]\n",
        "elif model_id == \"BioMistral/BioMistral-7B\":\n",
        "  specific_modules = [\"q_proj\",\"v_proj\",\"k_proj\",\"o_proj\"]\n",
        "elif model_id == \"stanford-crfm/BioMedLM\":\n",
        "  specific_modules = ['c_proj', 'c_attn']\n",
        "elif model_id == \"PharMolix/BioMedGPT-LM-7B\":\n",
        "  specific_modules = [\"q_proj\",\"v_proj\",\"k_proj\",\"o_proj\"]\n",
        "elif model_id ==  \"mistralai/Mistral-7B-Instruct-v0.1\":\n",
        "  specific_modules = ['k_proj', 'o_proj', 'v_proj', 'q_proj']\n",
        "elif model_id == \"facebook/opt-2.7b\":\n",
        "  specific_modules = ['out_proj', 'q_proj', 'v_proj', 'k_proj']\n",
        "elif model_id == \"meta-llama/Llama-2-7b-chat-hf\":\n",
        "  specific_modules = ['??????????????']\n",
        "else:\n",
        "  specific_modules = ['c_proj', 'c_attn']"
      ],
      "metadata": {
        "id": "G8sOaPp8KJYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(datasetname)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bN-LAJ_3ClGy",
        "outputId": "40189548-1a95-460b-d4cb-168620fde45b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_id2 = model_id.split('/')[1]"
      ],
      "metadata": {
        "id": "2SCJ9_VGXGx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RirOqanlguYb",
        "outputId": "2a3f26c8-c7a3-4f02-a0de-949b76151885"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.3.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.10/dist-packages (0.1.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacremoses) (2023.12.25)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses) (1.3.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sacremoses) (4.66.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn\n",
        "!pip install sacremoses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HckqrIjLem8w",
        "outputId": "d1fd440a-467b-4896-f839-f1d557be9a6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.38.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.1.0+cu121)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.27.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.27.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.1)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.17.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.25.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (23.2)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.13.1)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.9.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers[torch]\n",
        "!pip install accelerate -U\n",
        "!pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cguzURYmch4n",
        "outputId": "3257204e-8aeb-4a5b-de81-9ddf35a036e7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 10913\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 2729\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "2e91f36759044aeeb94c62b81cffc1ea",
            "9784f8d084744525b73a9bc819739191",
            "dbcfb6c216ae497cbdc7860e5aca4fb4",
            "700be781b7fc4d0a82b3ec952f56931f",
            "6734395273584e3d8305f44a165cd19f",
            "7f9ea4875c9145dea75911c1933a4b0a",
            "2fe4d39745b04299858a91b0ef09cb00",
            "8b70368f821b48c495658a6f6ba12eb9",
            "1f373953ef4a4c1f9c46410c2e00a238",
            "396e61bece6a45008e6485fa794e2979",
            "4907eece0ca94ca485819093a9bcdb0f",
            "cd8d1d44c6984f8baf71deae9d4a1023",
            "ebe1831669864c0cbed6bb30dd85cfc1",
            "64a28082074e435b8f050cb7a305f2e7",
            "22ac1cc7296f485f9dd2096a27bf3c16",
            "c34a38f0953448458ae3e0bcc3082b3e",
            "8dffb272c493482d996b36e5fb6f23e3",
            "8896582481fa447898165b756bfe406b",
            "d49b123e8247472f94b41af960c41d46",
            "fa084c853baf4c20a36e8aa045d4ed65",
            "34b89ce99a47435c98fadb0ef331dc0b",
            "5ad4f8c4032e45738f9c4c01975a0fa1"
          ]
        },
        "id": "2IFjXu1FdpSJ",
        "outputId": "b6e6057f-b277-49c8-f535-0ea5eeeac1a1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10913 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e91f36759044aeeb94c62b81cffc1ea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2729 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd8d1d44c6984f8baf71deae9d4a1023"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "tokenizer.pad_token=tokenizer.eos_token #remove\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True,max_length=512) #256 remove\n",
        "tokenized_datasets = dataset.map(tokenize_function) #removed batched=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1M6lYwJIeN5U"
      },
      "outputs": [],
      "source": [
        "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42) #.select(range(18812))\n",
        "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42) #.select(range(2000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uC5jshWRfUGU"
      },
      "outputs": [],
      "source": [
        "from transformers import BitsAndBytesConfig\n",
        "import torch\n",
        "bnb_config = BitsAndBytesConfig(load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "    bnb_4bit_use_double_quant=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKKrio43eTz0",
        "outputId": "ad9ee775-c6db-4833-c310-69e5457dadac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Some weights of OPTForSequenceClassification were not initialized from the model checkpoint at facebook/opt-2.7b and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "                                                model_id,\n",
        "                                                num_labels=2,\n",
        "                                                torch_dtype=torch.bfloat16,\n",
        "                                                quantization_config=bnb_config,#remove parameter for unquantized\n",
        "                                                use_cache=False\n",
        "                                            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dF7BlGrtYzY",
        "outputId": "440b1d00-0772-4922-9ad7-8025179729b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-03-01_21:53:47\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "now = datetime.now()\n",
        "date_time_string = now.strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
        "print(date_time_string)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-ywiWmtedJc"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "training_args = TrainingArguments(output_dir=\"test_trainer\"+date_time_string,\n",
        "                                  learning_rate=learning_rate,\n",
        "                                  evaluation_strategy=\"epoch\",\n",
        "                                  num_train_epochs=epoch,\n",
        "                                  save_steps=500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eEpwshWJeiG5"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8e-XF0lHeKdT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import evaluate\n",
        "metric = evaluate.load(\"accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PuWU12cYuhUJ"
      },
      "outputs": [],
      "source": [
        "import bitsandbytes as bnb\n",
        "def find_all_linear_names(model):\n",
        "  cls = bnb.nn.Linear4bit #if args.bits == 4 else (bnb.nn.Linear8bitLt if args.bits == 8 else torch.nn.Linear)\n",
        "  lora_module_names = set()\n",
        "  for name, module in model.named_modules():\n",
        "    if isinstance(module, cls):\n",
        "      names = name.split('.')\n",
        "      lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
        "\n",
        "\n",
        "# lm_head is often excluded.\n",
        "  if 'lm_head' in lora_module_names: # needed for 16-bit\n",
        "    lora_module_names.remove('lm_head')\n",
        "  return list(lora_module_names)\n",
        "\n",
        "modules = find_all_linear_names(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOqcYQvLvDhC",
        "outputId": "b7ac448f-bfa3-4821-e9c3-4c965b922563"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['k_proj', 'out_proj', 'fc1', 'q_proj', 'fc2', 'v_proj']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "modules"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#comment out to use all linear modules\n",
        "modules=specific_modules"
      ],
      "metadata": {
        "id": "pW70RjGzEuNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wutIqQRoguYf"
      },
      "outputs": [],
      "source": [
        "from peft import LoraConfig, TaskType\n",
        "dropout=0.20\n",
        "lora_config = LoraConfig(\n",
        "    task_type=TaskType.SEQ_CLS, r=4, lora_alpha=8, lora_dropout=dropout,target_modules=modules\n",
        ")\n",
        "\n",
        "#remove \"o_proj\"\n",
        "#target_modules=modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hP7dEiJguYg",
        "outputId": "f2cd684b-3f5e-4439-bb75-23293fbeb5b1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OPTForSequenceClassification(\n",
              "  (model): OPTModel(\n",
              "    (decoder): OPTDecoder(\n",
              "      (embed_tokens): Embedding(50272, 2560, padding_idx=1)\n",
              "      (embed_positions): OPTLearnedPositionalEmbedding(2050, 2560)\n",
              "      (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
              "      (layers): ModuleList(\n",
              "        (0-31): 32 x OPTDecoderLayer(\n",
              "          (self_attn): OPTAttention(\n",
              "            (k_proj): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
              "            (v_proj): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
              "            (q_proj): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
              "            (out_proj): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
              "          )\n",
              "          (activation_fn): ReLU()\n",
              "          (self_attn_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear4bit(in_features=2560, out_features=10240, bias=True)\n",
              "          (fc2): Linear4bit(in_features=10240, out_features=2560, bias=True)\n",
              "          (final_layer_norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (score): Linear(in_features=2560, out_features=2, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwI9IoKnguYg"
      },
      "outputs": [],
      "source": [
        "from peft import get_peft_model\n",
        "model = get_peft_model(model, lora_config)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_trainable_parameters(model):\n",
        "    \"\"\"\n",
        "    Prints the number of trainable parameters in the model.\n",
        "    \"\"\"\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(f\"Trainable params: {trainable_params} || All params: {all_param} || Trainable%: {100 * trainable_params / all_param}\")\n",
        "\n",
        "# Example usage (assuming a model variable exists)\n",
        "# print_trainable_parameters(model)"
      ],
      "metadata": {
        "id": "AmRMXarIFCXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxWfDQAOiKES"
      },
      "outputs": [],
      "source": [
        "#model.config.pad_token_id = model.config.eos_token_id #remove"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime"
      ],
      "metadata": {
        "id": "5yF5amCNI44l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29ISFcfioMrc"
      },
      "outputs": [],
      "source": [
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ze3T3e3GfY6R"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=small_train_dataset,\n",
        "    eval_dataset=small_eval_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if model_id == \"stanford-crfm/BioMedLM\":\n",
        "  model.config.pad_token_id=model.config.eos_token_id\n",
        "elif model_id == \"BioMistral/BioMistral-7B\":\n",
        "  model.config.pad_token_id=model.config.eos_token_id\n",
        "elif model_id == \"mistralai/Mistral-7B-Instruct-v0.1\":\n",
        "  model.config.pad_token_id=model.config.eos_token_id\n",
        "elif model_id == \"xxxxxxxxxxxxxxxxxxxx\":\n",
        "  model.config.pad_token_id=model.config.eos_token_id\n",
        "elif model_id == \"xxxxxxxxxxxxxxxxxxxx\":\n",
        "  model.config.pad_token_id=model.config.eos_token_id"
      ],
      "metadata": {
        "id": "F4K3QVS2i3al"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "s1POS2RvfvoE",
        "outputId": "e837132a-ebed-4637-9d4c-4036485d3553"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6825' max='6825' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6825/6825 1:07:03, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.251000</td>\n",
              "      <td>0.192913</td>\n",
              "      <td>0.939905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.175100</td>\n",
              "      <td>0.217700</td>\n",
              "      <td>0.943936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.102100</td>\n",
              "      <td>0.262072</td>\n",
              "      <td>0.944302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.049100</td>\n",
              "      <td>0.317970</td>\n",
              "      <td>0.950898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.019400</td>\n",
              "      <td>0.379682</td>\n",
              "      <td>0.951997</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import time\n",
        "t0 = time.time()\n",
        "trainer.train()\n",
        "training_time = format_time(time.time() - t0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SV2rH4waguYi"
      },
      "outputs": [],
      "source": [
        "trainer.model.save_pretrained(\"finetuned_model\"+model_id2+date_time_string)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFHGAmhpguYi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c5a909d-f252-453a-c1b9-08f07d64f203"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of OPTForSequenceClassification were not initialized from the model checkpoint at facebook/opt-2.7b and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "device_map = {\"\": 0}\n",
        "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_id,\n",
        "    num_labels=2,\n",
        "    low_cpu_mem_usage=True,\n",
        "    return_dict=True,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=device_map,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVIBbfh5miJI"
      },
      "outputs": [],
      "source": [
        "from peft import LoraConfig, PeftModel\n",
        "model = PeftModel.from_pretrained(base_model, \"finetuned_model\"+model_id2+date_time_string)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0tVZHlPmZfM"
      },
      "outputs": [],
      "source": [
        "model = model.merge_and_unload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPBARGBnmTLi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad55c4c9-8651-4810-d3c1-755e0677d8c4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "text = \"A 44-year-old man taking naproxen for chronic low back pain and a 20-year-old woman on oxaprozin for rheumatoid arthritis presented with tense bullae and cutaneous fragility on the face and the back of the hands.\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\").to(0)\n",
        "\n",
        "out = model(**inputs)\n",
        "logits=out.logits\n",
        "logits = logits.detach().cpu().numpy()\n",
        "np.argmax(logits, axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFz0aCLfzcbg"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import recall_score,f1_score,precision_score\n",
        "c=dataset[\"test\"][\"text\"]#[:4704]\n",
        "l=dataset[\"test\"][\"label\"]#[:4704]\n",
        "predicted=[]\n",
        "for item in c:\n",
        "    i=item\n",
        "    inputs = tokenizer(i, return_tensors=\"pt\").to(0)\n",
        "\n",
        "    out = model(**inputs)\n",
        "    logits=out.logits\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    predicted.append(np.argmax(logits, axis=-1)[0])\n",
        "conf = confusion_matrix(l,predicted)\n",
        "recall = recall_score(l,predicted, pos_label=1)\n",
        "f1 = f1_score(l,predicted, pos_label=1)\n",
        "precision = precision_score(l,predicted, pos_label=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "py_RnpvOoMrd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "#first time\n",
        "columns=[\"model_name\",\"Training Time\",\"precision\",\"recall\",\"f1_Score\",\"True Positives\",\"False Positives\",\"True Negatives\",\"False Negatives\",\"Epochs\",\"Learning Rate\",\"Drop Out\",\"Batch Size\",\"Weight Decay\"]\n",
        "df = pd.DataFrame(columns=columns)\n",
        "df.to_csv(f\"results_{datasetname.split('/')[1]}_FT_{model_id2}.csv\",index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_id3=f\"{datasetname.split('/')[1]}_{model_id}\""
      ],
      "metadata": {
        "id": "fXeoEwVpVnUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MnPu1KXOoMrd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "def add_row():\n",
        "  df=pd.read_csv(f\"results_{datasetname.split('/')[1]}_FT_{model_id2}.csv\")\n",
        "  data=[model_id3,training_time,precision,recall,f1,conf[0][0],conf[0][1],conf[1][1],conf[1][0],epoch,learning_rate,dropout,1,0]\n",
        "  df.loc[len(df)] = data\n",
        "  df.to_csv(f\"results_{datasetname.split('/')[1]}_FT_{model_id2}.csv\",index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "add_row()"
      ],
      "metadata": {
        "id": "6zhtEvdrOuKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mx_AdErMoMrd"
      },
      "outputs": [],
      "source": [
        "df_result= pd.DataFrame({\"text\":c,\"ground truth\":l,\"predictions\":predicted,\"model name\":model_id})\n",
        "df_result.to_csv(f\"testpreds_{datasetname.split('/')[1]}_FT_{model_id2}.csv\",index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.push_to_hub(f\"collij22/{datasetname.split('/')[1]}_FT_{model_id.split('/')[1]}\",token = \"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\")\n",
        "# tokenizer.push_to_hub(f\"collij22/{datasetname.split('/')[1]}_FT_{model_id.split('/')[1]}\",token = \"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\")\n"
      ],
      "metadata": {
        "id": "hObUDptlFiNU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}